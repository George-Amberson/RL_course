{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1NDjJiqysoT-"
   },
   "source": [
    "# Deep Q-Network implementation.\n",
    "\n",
    "This homework shamelessly demands you to implement DQN — an approximate Q-learning algorithm with experience replay and target networks — and see if it works any better this way.\n",
    "\n",
    "**Papers:**\n",
    "\n",
    "[1] Original paper, 2013: https://arxiv.org/pdf/1312.5602.pdf\n",
    "\n",
    "[2] Extended paper, Nature, 2015: https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf\n",
    "\n",
    "[3] Rainbow, 2017: https://arxiv.org/pdf/1710.02298.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BcLhaXMKsoT_"
   },
   "source": [
    "**This notebook is the main homework notebook.**\n",
    "Another notebook is given for debug: (**homework_pytorch_debug**). The debug notebook is not supported anymore, the codes have diverged. However, it can be useful in some cases. The tasks are similar and they used to share most of the code. The main difference is in environments. In main notebook it can take some 2 hours for the agent to start improving so it seems reasonable to launch the algorithm on a simpler env first. In debug one it is CartPole and it will train in several minutes.\n",
    "\n",
    "**About evaluation:** All points are only given for the main notebook.\n",
    "\n",
    "**Plan and evaluation points:**\n",
    "1. Getting to know the environment: most of the code is implemented for you\n",
    "2. DQN as it is (10 points): the main part of DQN implementation\n",
    "3. Main Loop (3 points): the training loop itself. Please, note, it can be really time-consuming, and implementation bugs can arise.\n",
    "4. Interpretation (2 points): calculation of episode statistics and their interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IVo0UxTWsoT_",
    "outputId": "f6753514-f89e-4d1f-e6bb-7e3a2b8ee4ed"
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "if 'google.colab' in sys.modules and not os.path.exists('.setup_complete'):\n",
    "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/setup_colab.sh -O- | bash\n",
    "\n",
    "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/week04_approx_rl/atari_wrappers.py\n",
    "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/week04_approx_rl/utils.py\n",
    "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/week04_approx_rl/replay_buffer.py\n",
    "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/week04_approx_rl/framebuffer.py\n",
    "\n",
    "    !touch .setup_complete\n",
    "\n",
    "# This code creates a virtual display to draw game images on.\n",
    "# It will have no effect if your machine has a monitor.\n",
    "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
    "    !bash ../xvfb start\n",
    "    os.environ['DISPLAY'] = ':1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KkrBeP7YsoUA"
   },
   "source": [
    "__Frameworks__ - we'll accept this homework in any deep learning framework. This particular notebook was designed for PyTorch, but you find it easy to adapt it to almost any Python-based deep learning framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "P8WoWe9DsoUA"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6GQBgViKsoUA"
   },
   "source": [
    "### Let's play some old videogames\n",
    "![img](https://github.com/yandexdataschool/Practical_RL/raw/master/yet_another_week/_resource/nerd.png)\n",
    "\n",
    "This time we're gonna apply approximate Q-learning to an Atari game called Breakout. It's not the hardest thing out there, but it's definitely way more complex than anything we have tried before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tYcadW6oIZzs"
   },
   "source": [
    "**These are various versions of Breakout provided by Gynmasium:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "51YY7_bSIZzt",
    "outputId": "e66c485a-d5f4-4b6b-acf3-8fd7fbd8e973"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Breakout-v0',\n",
       " 'BreakoutDeterministic-v0',\n",
       " 'BreakoutNoFrameskip-v0',\n",
       " 'Breakout-v4',\n",
       " 'BreakoutDeterministic-v4',\n",
       " 'BreakoutNoFrameskip-v4',\n",
       " 'Breakout-ram-v0',\n",
       " 'Breakout-ramDeterministic-v0',\n",
       " 'Breakout-ramNoFrameskip-v0',\n",
       " 'Breakout-ram-v4',\n",
       " 'Breakout-ramDeterministic-v4',\n",
       " 'Breakout-ramNoFrameskip-v4',\n",
       " 'ALE/Breakout-v5',\n",
       " 'ALE/Breakout-ram-v5']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_names = list(gym.envs.registry.keys())\n",
    "names_breakout = [name for name in all_names if \"Break\" in name]\n",
    "names_breakout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "S_zvw_31soUA"
   },
   "outputs": [],
   "source": [
    "ENV_NAME = \"ALE/Breakout-v5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JO9YPSn2IZzt"
   },
   "source": [
    "If you are curious about Atari environments in Gymnasium, please, refer to:\n",
    "- [4] Gymnasium docs: https://gymnasium.farama.org/environments/atari/\n",
    "- [5] Longer paper: https://arxiv.org/abs/1709.06009\n",
    "- [6] Shorter paper: https://www.ijcai.org/Proceedings/2018/0787.pdf\n",
    "\n",
    "For now it's enough to know about the v5 environments:\n",
    "- v5 environments are recommended for use\n",
    "- frame_skip=5, every 5-th frame is shown to the agent and the chosen action is executed for the next 5 moves\n",
    "- randomness comes from repeat_action_probability=0.25: with this probability the previous action is executed instead of the chosen action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xT9BvasNsoUA"
   },
   "source": [
    "## Getting to know the Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iwN8jA0OsoUA"
   },
   "source": [
    "**Let's see what observations look like.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "id": "_ZjQfwGkIZzt",
    "outputId": "99b5d66e-2c96-4dc8-d878-562b64737476"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n",
      "/home/george/envs/rlearn/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:335: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make(ENV_NAME, render_mode=\"rgb_array\")\n",
    "env.reset()\n",
    "plt.imshow(env.render())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vrK7yiYbIZzu"
   },
   "source": [
    "**Some more observations, coming from taking random actions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 511
    },
    "id": "rUZHU2HdsoUB",
    "outputId": "70937ce9-51ba-4c04-d826-1662953c55be"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABRAAAALDCAYAAABtkSyLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABso0lEQVR4nO39fXCddZ0Hfn+SPoQWmoa0tGmwpQV5UKEVEGJXF8tSaYs3CnR3Bess7LIUtODPVle2rjzOzl0U12XELqwzCustiOIorqzL3lCeZA0VCl0GxEK7haI0ZQWb9Clp01y/PyqnxPQqTXtOTs75vl4z35nmnCsn33OZ99trPpycU5NlWRYAAAAAAHtQW+4NAAAAAACDlwEiAAAAAJDLABEAAAAAyGWACAAAAADkMkAEAAAAAHIZIAIAAAAAuQwQAQAAAIBcBogAAAAAQC4DRAAAAAAglwEiAAAAAJCrrAPEpUuXxuTJk+Oggw6KlpaW+OUvf1nO7QADSP4hbToA0iX/kDYdAJWpbAPE73//+7Fo0aK45ppr4qmnnopp06bFrFmz4rXXXivXloABIv+QNh0A6ZJ/SJsOgMpVk2VZVo4f3NLSEqecckp84xvfiIiInp6emDhxYlxxxRXx93//9+XYEjBA5B/SpgMgXfIPadMBULmGluOHbt++PVasWBGLFy8u3FZbWxszZ86M1tbWPsd3dXVFV1dX4euenp544403YsyYMVFTUzMge4Zql2VZbNq0KZqbm6O2tnQvTu5v/iN0AJTaQOU/wjUADEauASBtg7UD5B9Krz/5L8sA8Xe/+13s3Lkzxo8f3+v28ePHx69//es+xy9ZsiSuu+66gdoeJO2VV16Jd7zjHSV7/P7mP0IHwEApdf4jXAPAYOYaANI22DpA/mHg7Ev+K+JTmBcvXhzt7e2FtW7dunJvCarWqFGjyr2FPnQADAz5h7TpAEjbYOsA+YeBsy/5L8srEMeOHRtDhgyJDRs29Lp9w4YN0dTU1Of4urq6qKurG6jtQdJK/ecA/c1/hA6AgTIQfw7kGgAGL9cAkLbB1gHyDwNnX/JfllcgDh8+PE4++eRYtmxZ4baenp5YtmxZTJ8+vRxbAgaI/EPadACkS/4hbToAKlxWJnfddVdWV1eX3X777dmvfvWrbP78+VlDQ0PW1tb2tt/b3t6eRYRlWSVY7e3tgzr/WaYDLKtUayDyn2WuASxrsC7XAJaV9hrsHSD/llW6tS/5L8ufMEdEfPzjH4//+7//i6uvvjra2trive99b9x333193lC1Wr3zne+MYcOG7ff3r1mzJrZv397rtsbGxgM6fxs3boz169f3uq22tjaOOeaY/X45e09PT7zwwguRZdl+72tfjRgxIiZPnrzf39/Z2Rlr164t3ob6aejQoXH00Uf3uX3t2rXR2dlZhh2VTur5j9ABpaADKkfqHSD/xSf/lSP1/EfogFLQAZUj9Q6Q/+KT/4FTkw3E/6JF1tHREaNHjy73Ng7IP/zDP8SYMWP2+/u//OUv93nviBkzZsRHP/rR/X7Mxx9/PH7wgx/0um3EiBFx/fXXx5AhQ/brMbdv3x5XXXVV7NixY7/3ta8mT54cn/nMZ/b7+1999dX46le/WsQd9U99fX1cc801fUr6pptuGtA3DG5vb4/6+voB+3n7QwfogD3RAQdO/geG/Bef/BeHDhgYOqD4dEBxDPYOkH/53xP5L459yX9FfAozAAAAAFAeZfsTZvpauXJl/M///E+v20aNGhXnnnvufr90eOvWrfHDH/6wz0uHzzrrrDjssMP2e6/3339/vPrqq71umzx5cnzoQx/a78cshSzL4u67745t27a97bGD7eXBpEcHFJ8OoFLIf/HJP5VEBxSfDqBSyH/xyX9pGCAOIm1tbX2KY8yYMXHuuefu92Pu2LEjVq5c2ef2GTNm7PdjRux674UXXnihz+2DsTieffbZ2Lx5c7m3Am9LBxSfDqBSyH/xyT+VRAcUnw6gUsh/8cl/aRggUvWGDBmyT+/dkGVZ9PT0DMCOgIGkAyBd8g9p0wGQLvkvPgNEqlpNTU1ceeWV+/TpT21tbXHzzTcPwK6AgaIDIF3yD2nTAZAu+S8NA0SqWk1NTRx00EH7dGxdXV2JdwMMNB0A6ZJ/SJsOgHTJf2kYIFI1tm3bFi+++OI+HXvYYYdFQ0NDaTcEDCgdAOmSf0ibDoB0yf/AMUCkamzYsCFuueWWfTr2nHPOidNOO63EOwIGkg6AdMk/pE0HQLrkf+DUlnsDAAAAAMDg5RWIg8gJJ5wQY8aM6XXbgf49/ogRI+KCCy7oc/sf/5z+Ov300+Pkk0/udduhhx56QI95oMaOHRsf/vCH9+nYSZMmlXg30H864MDoACqZ/B8Y+afS6YADowOoZPJ/YOR/4BggDiKHH354HH744UV9zOHDh8cpp5xS1MeMiDj22GOL/pgH6pBDDinJc4WBogMOjA6gksn/gZF/Kp0OODA6gEom/wdG/geOAWKZ9PT0xM6dO4v6mFmWHdBj5n3EeU9Pz34/5oF8b38d6PMfyL0O5j0wMHRA8ekAKoX8F5/8U0l0QPHpACqF/Bef/A+cmizvt2UQ6+joiNGjR5d7GwdkxIgRUVNTs9/fv23btj5BHzp0aAwfPny/H7O7uzu2b9/e5/aRI0fu92NGRGzduvWAvn9f1dbW7vNHte9JT09PdHZ2FnFH/VNTUxMjRozoc3tnZ+eAFkp7e3vU19cP2M/bHzpAB+yJDjhw8j8w5L/45L84dMDA0AHFpwOKY7B3gPzL/57If3HsS/69ArFMtm3bVvTH7O7uju7u7qI/7kAF/0D19PRUzF73JMuyit4//aMDik8HUCnkv/jkn0qiA4pPB1Ap5L/45H/gVPQA8YgjjojaWh8kDcXQ09MTL7/8crm30S86AIpD/iFtOgDSVmkdIP9QPP3Jf0UPEC+99NIDeqkqsFtnZ2d88YtfLPc2+kUHQHHIP6RNB0DaKq0D5B+Kpz/5N7YHAAAAAHIZIAIAAAAAuQwQAQAAAIBcBogAAAAAQC4DRAAAAAAglwEiAAAAAJCr6APEJUuWxCmnnBKjRo2KcePGxTnnnBOrVq3qdcyMGTOipqam17rsssuKvRVggMk/pE0HQNp0AKRL/qH6FX2A+Mgjj8SCBQvi8ccfj/vvvz927NgRZ555ZmzZsqXXcZdcckmsX7++sL7yla8UeyvAAJN/SJsOgLTpAEiX/EP1G1rsB7zvvvt6fX377bfHuHHjYsWKFXHaaacVbh85cmQ0NTUV+8cDZST/kDYdAGnTAZAu+YfqV/L3QGxvb4+IiMbGxl6333HHHTF27Ng4/vjjY/HixbF169ZSbwUYYPIPadMBkDYdAOmSf6g+RX8F4lv19PTEZz/72fjABz4Qxx9/fOH2T3ziE3HEEUdEc3NzPPPMM3HllVfGqlWr4kc/+tEeH6erqyu6uroKX3d0dJRy20ARFCv/EToAKpFrAEibDoB0yT9Up5IOEBcsWBDPPvtsPPbYY71unz9/fuHfJ5xwQkyYMCHOOOOMWLNmTRx11FF9HmfJkiVx3XXXlXKrQJEVK/8ROgAqkWsASJsOgHTJP1Snkv0J8+WXXx733ntvPPTQQ/GOd7xjr8e2tLRERMTq1av3eP/ixYujvb29sF555ZWi7xconmLmP0IHQKVxDQBp0wGQLvmH6lX0VyBmWRZXXHFF/PjHP46HH344pkyZ8rbfs3LlyoiImDBhwh7vr6uri7q6umJuEyiBUuQ/QgdApXANAGnTAZAu+YfqV/QB4oIFC+LOO++Mn/zkJzFq1Khoa2uLiIjRo0fHiBEjYs2aNXHnnXfGWWedFWPGjIlnnnkmFi5cGKeddlpMnTq12NsBBpD8Q9p0AKRNB0C65B+qX9EHiLfccktERMyYMaPX7bfddltcdNFFMXz48HjggQfipptuii1btsTEiRNj7ty58aUvfanYWwEGmPxD2nQApE0HQLrkH6pfSf6EeW8mTpwYjzzySLF/LDAIyD+kTQdA2nQApEv+ofqV7ENUAAAAAIDKV/RXIA42XV1d8fvf/77c24CyOfTQQ5N+82EdQOpS7gD5J3Up5z9CB0DKHSD/pK4U+a/6AeLatWvjm9/8Zrm3AWVz6aWXxrHHHlvubZSNDiB1KXeA/JO6lPMfoQMg5Q6Qf1JXivz7E2YAAAAAIJcBIgAAAACQywARAAAAAMhlgAgAAAAA5DJABAAAAAByGSACAAAAALkMEAEAAACAXAaIAAAAAEAuA0QAAAAAIJcBIgAAAACQywARAAAAAMhlgAgAAAAA5DJABAAAAAByGSACAAAAALkMEAEAAACAXAaIAAAAAEAuA0QAAAAAIJcBIgAAAACQywARAAAAAMhlgAgAAAAA5Cr6APHaa6+NmpqaXuu4444r3N/Z2RkLFiyIMWPGxCGHHBJz586NDRs2FHsbQBnIP6RNB0DadACkS/6h+pXkFYjvec97Yv369YX12GOPFe5buHBh/PSnP4277747HnnkkXj11VfjvPPOK8U2gDKQf0ibDoC06QBIl/xDdRtakgcdOjSampr63N7e3h7f+ta34s4774w/+7M/i4iI2267Ld71rnfF448/Hu9///tLsR1gAMk/pE0HQNp0AKRL/qG6leQViC+++GI0NzfHkUceGfPmzYt169ZFRMSKFStix44dMXPmzMKxxx13XEyaNClaW1tzH6+rqys6Ojp6LWBwKnb+I3QAVBLXAJA2HQDpkn+obkUfILa0tMTtt98e9913X9xyyy2xdu3a+NM//dPYtGlTtLW1xfDhw6OhoaHX94wfPz7a2tpyH3PJkiUxevTowpo4cWKxtw0UQSnyH6EDoFK4BoC06QBIl/xD9Sv6nzDPmTOn8O+pU6dGS0tLHHHEEfGDH/wgRowYsV+PuXjx4li0aFHh646ODuUBg1Ap8h+hA6BSuAaAtOkASJf8Q/UryZ8wv1VDQ0Mcc8wxsXr16mhqaort27fHxo0bex2zYcOGPb5Xwpvq6uqivr6+1wIGv2LkP0IHQKVyDQBp0wGQLvmH6lPyAeLmzZtjzZo1MWHChDj55JNj2LBhsWzZssL9q1atinXr1sX06dNLvRVggMk/pE0HQNp0AKRL/qH6FP1PmD//+c/H2WefHUcccUS8+uqrcc0118SQIUPiggsuiNGjR8fFF18cixYtisbGxqivr48rrrgipk+f7pOXoArIP6RNB0DadACkS/6h+hV9gPib3/wmLrjggnj99dfjsMMOiw9+8IPx+OOPx2GHHRYREf/8z/8ctbW1MXfu3Ojq6opZs2bFv/zLvxR7G0AZyD+kTQdA2nQApEv+ofoVfYB411137fX+gw46KJYuXRpLly4t9o8Gykz+IW06ANKmAyBd8g/Vr+TvgQgAAAAAVK6ivwJxsHn36NFx66mnlnsbUDado0dHT7k3UUY6gNSl3AHyT+pSzn+EDoCUO0D+SV0p8l/1A8T6YcPi3Y2N5d4GlM1zw4ZFe7k3UUY6gNSl3AHyT+pSzn+EDoCUO0D+SV0p8u9PmAEAAACAXAaIAAAAAEAuA0QAAAAAIJcBIgAAAACQywARAAAAAMhlgAgAAAAA5Bpa7g2UWla3M3qat5R7G1A+dTvLvYOy0gEkL+EOkH+Sl3D+I3QApNwB8k/ySpD/qh8gxpAsYmS6xQlRm5V7B+WlA0hdyh0g/6Qu5fxH6ABIuQPkn9SVIP/+hBkAAAAAyGWACAAAAADkMkAEAAAAAHIZIAIAAAAAuQwQAQAAAIBcBogAAAAAQK6h5d5Aqe0c0hObRnSWextQNt1Desq9hbLSAaQu5Q6Qf1KXcv4jdACk3AHyT+pKkf+qHyD21GSxY1i6xQlZTVbuLZSVDiB1KXeA/JO6lPMfoQMg5Q6Qf1JXivz7E2YAAAAAIJcBIgAAAACQywARAAAAAMhV9AHi5MmTo6amps9asGBBRETMmDGjz32XXXZZsbcBlIkOgHTJP6RNB0C65B+qX9E/ROWJJ56InTt3Fr5+9tln48Mf/nD8xV/8ReG2Sy65JK6//vrC1yNHjiz2NoAy0QGQLvmHtOkASJf8Q/Ur+gDxsMMO6/X1DTfcEEcddVR86EMfKtw2cuTIaGpqKvaPBgYBHQDpkn9Imw6AdMk/VL+iDxDfavv27fHd7343Fi1aFDU1NYXb77jjjvjud78bTU1NcfbZZ8dVV11Vsv/6sLMui03NO0ry2FAJdu7IIor/Ce77RAdA+ZWrA+Qfys81gA4gba4B5J90lSL/JR0g3nPPPbFx48a46KKLCrd94hOfiCOOOCKam5vjmWeeiSuvvDJWrVoVP/rRj3Ifp6urK7q6ugpfd3R07PMeeoZmsaO+TFdOMAj0tEdEmf6/UwdA+ZWrA+Qfys81gA4gba4B5J90lSL/JR0gfutb34o5c+ZEc3Nz4bb58+cX/n3CCSfEhAkT4owzzog1a9bEUUcdtcfHWbJkSVx33XWl3CpQAjoA0iX/kDYdAOmSf6hORf8U5je9/PLL8cADD8Tf/u3f7vW4lpaWiIhYvXp17jGLFy+O9vb2wnrllVeKuleg+HQApEv+IW06ANIl/1C9SvYKxNtuuy3GjRsXH/nIR/Z63MqVKyMiYsKECbnH1NXVRV1dXTG3B5SYDoB0yT+kTQdAuuQfqldJBog9PT1x2223xYUXXhhDh+7+EWvWrIk777wzzjrrrBgzZkw888wzsXDhwjjttNNi6tSppdgKUAY6ANIl/5A2HQDpkn+obiUZID7wwAOxbt26+Ju/+Ztetw8fPjweeOCBuOmmm2LLli0xceLEmDt3bnzpS18qxTaAMtEBkC75h7TpAEiX/EN1K8kA8cwzz4ws6/uJRxMnToxHHnmkFD8SGER0AKRL/iFtOgDSJf9Q3Ur6KcyDwcYYHs/1jCn3NqBsDo9hcXC5N1FGOoDUpdwB8k/qUs5/hA6AlDtA/kldKfJf9QPEbTEkXkq2NiFiTDYk6QToAFKXcgfIP6lLOf8ROgBS7gD5J3WlyH9tkR8PAAAAAKgiBogAAAAAQC4DRAAAAAAglwEiAAAAAJDLABEAAAAAyGWACAAAAADkGlruDZRa1j4uup8/u9zbgLLJmrdHjMzKvY2y0QGkLuUOkH9Sl3L+I3QApNwB8k/qSpH/6h8gbq2Pnv99d7m3AWWTHfpcxMj2cm+jbHQAqUu5A+Sf1KWc/wgdACl3gPyTulLk358wAwAAAAC5DBABAAAAgFwGiAAAAABALgNEAAAAACCXASIAAAAAkMsAEQAAAADINbTcGyi1rZtfihd+9Z/l3gaUzQnHvitiTEO5t1E2OoDUpdwB8k/qUs5/hA6AlDtA/kldKfJf9QPEzs62+M26u8u9DSibzs5LI6Kh3NsoGx1A6lLuAPkndSnnP0IHQModIP+krhT59yfMAAAAAEAuA0QAAAAAIJcBIgAAAACQywARAAAAAMhlgAgAAAAA5Or3APHRRx+Ns88+O5qbm6OmpibuueeeXvdnWRZXX311TJgwIUaMGBEzZ86MF198sdcxb7zxRsybNy/q6+ujoaEhLr744ti8efMBPRGg9OQf0qYDIF3yD2nTAUC/B4hbtmyJadOmxdKlS/d4/1e+8pX4+te/HrfeemssX748Dj744Jg1a1Z0dnYWjpk3b14899xzcf/998e9994bjz76aMyfP3//nwUwIOQf0qYDIF3yD2nTAcDQ/n7DnDlzYs6cOXu8L8uyuOmmm+JLX/pSfOxjH4uIiO985zsxfvz4uOeee+L888+P559/Pu6777544okn4n3ve19ERNx8881x1llnxVe/+tVobm4+gKcDlJL8Q9p0AKRL/iFtOgAo6nsgrl27Ntra2mLmzJmF20aPHh0tLS3R2toaERGtra3R0NBQKI2IiJkzZ0ZtbW0sX758j4/b1dUVHR0dvRYwuJQq/xE6ACqBawBIl2sASJtrAEhDUQeIbW1tERExfvz4XrePHz++cF9bW1uMGzeu1/1Dhw6NxsbGwjF/bMmSJTF69OjCmjhxYjG3DRRBqfIfoQOgErgGgHS5BoC0uQaANFTEpzAvXrw42tvbC+uVV14p95aAAaQDIF3yD2nTAZAu+YfBpagDxKampoiI2LBhQ6/bN2zYULivqakpXnvttV73d3d3xxtvvFE45o/V1dVFfX19rwUMLqXKf4QOgErgGgDS5RoA0uYaANJQ1AHilClToqmpKZYtW1a4raOjI5YvXx7Tp0+PiIjp06fHxo0bY8WKFYVjHnzwwejp6YmWlpZibgcYQPIPadMBkC75h7TpAEhDvz+FefPmzbF69erC12vXro2VK1dGY2NjTJo0KT772c/GP/7jP8bRRx8dU6ZMiauuuiqam5vjnHPOiYiId73rXTF79uy45JJL4tZbb40dO3bE5ZdfHueff75PXoJBTv4hbToA0iX/kDYdAPR7gPjkk0/G6aefXvh60aJFERFx4YUXxu233x5f+MIXYsuWLTF//vzYuHFjfPCDH4z77rsvDjrooML33HHHHXH55ZfHGWecEbW1tTF37tz4+te/XoSnA5SS/EPadACkS/4hbToA6PcAccaMGZFlWe79NTU1cf3118f111+fe0xjY2Pceeed/f3RQJnJP6RNB0C65B/SpgOAivgUZgAAAACgPAwQAQAAAIBcBogAAAAAQC4DRAAAAAAglwEiAAAAAJDLABEAAAAAyGWACAAAAADkMkAEAAAAAHIZIAIAAAAAuQwQAQAAAIBcBogAAAAAQC4DRAAAAAAglwEiAAAAAJDLABEAAAAAyGWACAAAAADkMkAEAAAAAHIZIAIAAAAAuQwQAQAAAIBcBogAAAAAQC4DRAAAAAAglwEiAAAAAJDLABEAAAAAyNXvAeKjjz4aZ599djQ3N0dNTU3cc889hft27NgRV155ZZxwwglx8MEHR3Nzc/zVX/1VvPrqq70eY/LkyVFTU9Nr3XDDDQf8ZIDSkn9Imw6AdMk/pE0HAP0eIG7ZsiWmTZsWS5cu7XPf1q1b46mnnoqrrroqnnrqqfjRj34Uq1atio9+9KN9jr3++utj/fr1hXXFFVfs3zMABoz8Q9p0AKRL/iFtOgAY2t9vmDNnTsyZM2eP940ePTruv//+Xrd94xvfiFNPPTXWrVsXkyZNKtw+atSoaGpq6u+PB8pI/iFtOgDSJf+QNh0AlPw9ENvb26OmpiYaGhp63X7DDTfEmDFj4sQTT4wbb7wxuru7cx+jq6srOjo6ei1g8CtG/iN0AFQq1wBp+H+OOy6+2dISN7/vfTG0pqbc22GQcA0AaXMNANWn369A7I/Ozs648sor44ILLoj6+vrC7Z/5zGfipJNOisbGxvjFL34RixcvjvXr18fXvva1PT7OkiVL4rrrrivlVoEiK1b+I3QAVCLXAOmYfPDBMfXQQ2Nrd3fU1tREZFm5t0SZuQaAtLkGgOpUsgHijh074i//8i8jy7K45ZZbet23aNGiwr+nTp0aw4cPj0svvTSWLFkSdXV1fR5r8eLFvb6no6MjJk6cWKqtAweomPmP0AFQaVwDQLpcA0DaXANA9SrJAPHN0nj55ZfjwQcf7PVfHfakpaUluru746WXXopjjz22z/11dXW5FxXA4FLs/EfoAKgkrgEgXa4BIG2uAaC6FX2A+GZpvPjii/HQQw/FmDFj3vZ7Vq5cGbW1tTFu3LhibwcYQPIPadMBkC75h7TpAKh+/R4gbt68OVavXl34eu3atbFy5cpobGyMCRMmxJ//+Z/HU089Fffee2/s3Lkz2traIiKisbExhg8fHq2trbF8+fI4/fTTY9SoUdHa2hoLFy6MT37yk3HooYcW75kBRSf/kDYdwJ488frr8cb27bG9pyd2ev/DqiX/DK2piZkTJkRtRLy6bVus/P3vy70lBpAOAPo9QHzyySfj9NNPL3z95nsSXHjhhXHttdfGv//7v0dExHvf+95e3/fQQw/FjBkzoq6uLu6666649tpro6urK6ZMmRILFy7s9d4GwOAk/5A2HcCe3PnSS+XeAgNA/jloyJD4h+OPj2G1tfH/f/VVA8TE6ACg3wPEGTNmRLaX/7q8t/siIk466aR4/PHH+/tjgUFA/iFtOgDSJf+QNh0A1JZ7AwAAAADA4GWACAAAAADkKvqnMAMAAFBdsojY0t0dQ2tqorOnp9zbAUpkaE1N1A0ZEhER23bujB4fkMYfGCACAACwV1u6u+P/89BDEbFrmAhUpw9PmBBfPP74iIj4zBNPxNM+MIk/MEAEAADgbXV7JRJUvdqamhhWu+vd7mpqasq8GwYT74EIAAAAAOQyQAQAAAAAchkgAgAAAAC5vAciAAAAAPHL3/0uFj75ZERErN60qcy7YTAxQAQAAAAg/q+rK/6vq6vc22AQ8ifMAAAAAEAuA0QAAAAAIJcBIgAAAACQywARAAAAAMhlgAgAAAAA5DJABAAAAAByGSACAAAAALkMEAEAAACAXAaIAAAAAEAuA0QAAAAAIJcBIgAAAACQywARAAAAAMjV7wHio48+GmeffXY0NzdHTU1N3HPPPb3uv+iii6KmpqbXmj17dq9j3njjjZg3b17U19dHQ0NDXHzxxbF58+YDeiJA6ck/pE0HQLrkH9KmA4B+DxC3bNkS06ZNi6VLl+YeM3v27Fi/fn1hfe973+t1/7x58+K5556L+++/P+6999549NFHY/78+f3fPTCg5B/SpgMgXfIPadMBwND+fsOcOXNizpw5ez2mrq4umpqa9njf888/H/fdd1888cQT8b73vS8iIm6++eY466yz4qtf/Wo0Nzf3d0vAAJF/SJsOgHTJP6RNBwAleQ/Ehx9+OMaNGxfHHntsfOpTn4rXX3+9cF9ra2s0NDQUSiMiYubMmVFbWxvLly8vxXaAAST/kDYdAOmSf0ibDoDq1u9XIL6d2bNnx3nnnRdTpkyJNWvWxBe/+MWYM2dOtLa2xpAhQ6KtrS3GjRvXexNDh0ZjY2O0tbXt8TG7urqiq6ur8HVHR0extw0UQSnyH6EDoFK4BoB0uQaAtLkGgOpX9AHi+eefX/j3CSecEFOnTo2jjjoqHn744TjjjDP26zGXLFkS1113XbG2CJRIKfIfoQOgUrgGgHS5BoC0uQaA6leSP2F+qyOPPDLGjh0bq1evjoiIpqameO2113od093dHW+88Ubu+yUsXrw42tvbC+uVV14p9baBIihG/iN0AFQq1wCQLtcAkDbXAFB9Sj5A/M1vfhOvv/56TJgwISIipk+fHhs3bowVK1YUjnnwwQejp6cnWlpa9vgYdXV1UV9f32sBg18x8h+hA6BSuQaAdLkGgLS5BoDq0+8/Yd68eXPhvyJERKxduzZWrlwZjY2N0djYGNddd13MnTs3mpqaYs2aNfGFL3wh3vnOd8asWbMiIuJd73pXzJ49Oy655JK49dZbY8eOHXH55ZfH+eef75OXYJCTf0ibDoB0yT+kTQcA/X4F4pNPPhknnnhinHjiiRERsWjRojjxxBPj6quvjiFDhsQzzzwTH/3oR+OYY46Jiy++OE4++eT4+c9/HnV1dYXHuOOOO+K4446LM844I84666z44Ac/GN/85jeL96yAkpB/SJsOgHTJP6RNBwD9fgXijBkzIsuy3Pv/67/+620fo7GxMe68887+/migzOQf0qYDIF3yD2nTAUDJ3wMRAAAAAKhcBogAAAAAQC4DRAAAAAAglwEiAAAAAJDLABEAAAAAyGWACAAAAADkMkAEAAAAAHIZIAIAAAAAuQwQAQAAAIBcBogAAAAAQC4DRAAAAAAglwEiAAAAAJDLABEAAAAAyGWACAAAAADkMkAEAAAAAHIZIAIAAAAAuQwQAQAAAIBcBogAAAAAQC4DRAAAAAAglwEiAAAAAJDLABEAAAAAyGWACAAAAADkMkAEAAAAAHL1e4D46KOPxtlnnx3Nzc1RU1MT99xzT6/7a2pq9rhuvPHGwjGTJ0/uc/8NN9xwwE8GKC35h7TpAEiX/EPadADQ7wHili1bYtq0abF06dI93r9+/fpe69vf/nbU1NTE3Llzex13/fXX9zruiiuu2L9nAAwY+Ye06QBIl/xD2nQAMLS/3zBnzpyYM2dO7v1NTU29vv7JT34Sp59+ehx55JG9bh81alSfY4HBTf4hbToA0iX/kDYdAJT0PRA3bNgQ//Ef/xEXX3xxn/tuuOGGGDNmTJx44olx4403Rnd3d+7jdHV1RUdHR68FDG7Fyn+EDoBK5BoA0uUaANLmGgCqU79fgdgf//Zv/xajRo2K8847r9ftn/nMZ+Kkk06KxsbG+MUvfhGLFy+O9evXx9e+9rU9Ps6SJUviuuuuK+VWgSIrVv4jdABUItcAkC7XAJA21wBQnUo6QPz2t78d8+bNi4MOOqjX7YsWLSr8e+rUqTF8+PC49NJLY8mSJVFXV9fncRYvXtzrezo6OmLixIml2zhwwIqV/wgdAJXINQCkyzUApM01AFSnkg0Qf/7zn8eqVavi+9///tse29LSEt3d3fHSSy/Fscce2+f+urq63IsKYPApZv4jdABUGtcAkC7XAJA21wBQvUr2Hojf+ta34uSTT45p06a97bErV66M2traGDduXKm2Awwg+Ye06QBIl/xD2nQAVK9+vwJx8+bNsXr16sLXa9eujZUrV0ZjY2NMmjQpIna9tPjuu++Of/qnf+rz/a2trbF8+fI4/fTTY9SoUdHa2hoLFy6MT37yk3HooYcewFMBSk3+IW06ANIl/5A2HQD0e4D45JNPxumnn174+s33JLjwwgvj9ttvj4iIu+66K7IsiwsuuKDP99fV1cVdd90V1157bXR1dcWUKVNi4cKFvd7bABic5B/SpgMgXfIPadMBQL8HiDNmzIgsy/Z6zPz582P+/Pl7vO+kk06Kxx9/vL8/FhgE5B/SpgMgXfIPadMBQMneAxEAAAAAqHwGiAAAAABALgNEAAAAACCXASIAAAAAkMsAEQAAAADIZYAIAAAAAOQyQAQAAAAAchkgAgAAAAC5DBABAAAAgFwGiAAAAABArqHl3sCB6Kzpiajp2esx22uyAdoN5XTw0KFx0JAhRX3MnT09sXHHjqI+ZjkM3bEjhnV1ve1x3ftwzGCjA3iTDsi3Lx0g/1Qy+c/nGkAHpEAH5KvWDpB/3iT/+UqR/4oeID48amsMHbH34nh9ZOcA7YZy+syxx8bZ73hHUR9z7ebNMe+//7uoj1kOxzzzTLzv1Vff9rgt3d0DsJvi0gG8SQfk25cOkH8qmfzncw2gA1KgA/JVawfIP2+S/3ylyH9FDxCj5g8LIqK2pri/DNXyq7WvManI56sDeAsdsGf7EpOKfK7yz1vI/565BiAVOmDPqrYD5J+3kP89K0X+vQciAAAAAJDLABEAAAAAyGWACAAAAADkquz3QIQ/+M7//m/89Le/Lepjdu7cWdTHA0pHB0C65B/SpgMgXfI/sAwQqQq/3bYtfrttW7m3AZSJDoB0yT+kTQdAuuR/YBkgQpXb3N0dv9++/W2P68/HtwOVY186QP6hOrkGgLTpAEhXKfJvgAhV7h9Wrtynj2bPSr4ToBz2pQPkH6qTawBImw6AdJUi/xU9QFz5T9+Jmtq9fw5M91YvZyVtWVTvRYEOgLdXrR0g//D2qjX/EToA9kW1doD8w9srRf4reoDY8b+/KfcWgDLSAZAu+Ye06QBIl/xDeex9bP9HlixZEqecckqMGjUqxo0bF+ecc06sWrWq1zGdnZ2xYMGCGDNmTBxyyCExd+7c2LBhQ69j1q1bFx/5yEdi5MiRMW7cuPi7v/u76Pa+CzDo6QBIl/xD2nQApEv+gYiIyPph1qxZ2W233ZY9++yz2cqVK7OzzjormzRpUrZ58+bCMZdddlk2ceLEbNmyZdmTTz6Zvf/978/+5E/+pHB/d3d3dvzxx2czZ87Mnn766exnP/tZNnbs2Gzx4sX7vI/29vY3X41pWVaRV3t7uw6wrESX/FtW2ksHWFbaK68D5N+yqn/t7RrgTf0aIP6x1157LYuI7JFHHsmyLMs2btyYDRs2LLv77rsLxzz//PNZRGStra1ZlmXZz372s6y2tjZra2srHHPLLbdk9fX1WVdX1z79XMVhWaVb+1IcOsCyqnPJv2WlvXSAZaW99rUD5N+yqm/tS/779SfMf6y9vT0iIhobGyMiYsWKFbFjx46YOXNm4ZjjjjsuJk2aFK2trRER0draGieccEKMHz++cMysWbOio6MjnnvuuQPZDjDAdACkS/4hbToA0iX/kKb9/hCVnp6e+OxnPxsf+MAH4vjjj4+IiLa2thg+fHg0NDT0Onb8+PHR1tZWOOatpfHm/W/etyddXV3R1dVV+Lqjo2N/tw0UiQ6AdMk/pE0HQLrkH9K1369AXLBgQTz77LNx1113FXM/e7RkyZIYPXp0YU2cOLHkPxPYOx0A6ZJ/SJsOgHTJP6RrvwaIl19+edx7773x0EMPxTve8Y7C7U1NTbF9+/bYuHFjr+M3bNgQTU1NhWP++NOY3vz6zWP+2OLFi6O9vb2wXnnllf3ZNlAkOgDSJf+QNh0A6ZJ/SNw+vVvpH/T09GQLFizImpubsxdeeKHP/W++eeoPf/jDwm2//vWvs4i+b566YcOGwjH/+q//mtXX12ednZ37tA9vnmpZpVt7e/NUHWBZ1b3k37LSXjrAstJeeR0g/5ZV/avon8L8qU99Khs9enT28MMPZ+vXry+srVu3Fo657LLLskmTJmUPPvhg9uSTT2bTp0/Ppk+fXrj/zY9vP/PMM7OVK1dm9913X3bYYYf5+HbLGiRrb8WhAyyrupf8W1baSwdYVtorrwPk37KqfxV9gJj3g2677bbCMdu2bcs+/elPZ4ceemg2cuTI7Nxzz83Wr1/f63FeeumlbM6cOdmIESOysWPHZp/73OeyHTt27PM+FIdllW7trTjyvkcHWFZ1LPm3rLSXDrCstFdeB+QdL/+WVT1rXwaINX8ohIrS0dERo0ePLvc2oCq1t7dHfX19ubexVzoASkP+IW06ANI22DtA/qF09iX/+/0pzAAAAABA9TNABAAAAAByGSACAAAAALkMEAEAAACAXAaIAAAAAECuihwgVuAHR0PFqIR8VcIeoRJVQrYqYY9QqSohX5WwR6hUgz1fg31/UMn2JV8VOUDctGlTubcAVasS8vX666+XewtQlSoh/5WwR6hUlZAv1wBQOoO9Awb7/qCS7Uu+arIKHOP39PTEqlWr4t3vfne88sorUV9fX+4tlVVHR0dMnDgx+XPhPOy2P+ciy7LYtGlTNDc3R23t4P5vCxs3boxDDz001q1bF6NHjy73dsrK7/1uzsVu/T0XlZR/1wC9+b3fxXnYzTVAOvze7+Zc7FbNHeAaoDe/97s5F7uUOv9Di7HJgVZbWxuHH354RETU19cn/QvyVs7FLs7Dbv09F5VyIf5msY0ePdr/1n/g934352K3/pyLSsq/a4C+nItdnIfdXAOkw+/9bs7FbtXYAa4B9sy52M252KVU+R+8/3kBAAAAACg7A0QAAAAAIFfFDhDr6urimmuuibq6unJvpeyci12ch92q/VxU+/PrD+diN+dit2o/F9X+/PrDudjFedit2s9FtT+//nAudnMudqv2c1Htz68/nIvdnItdSn0eKvJDVAAAAACAgVGxr0AEAAAAAErPABEAAAAAyGWACAAAAADkMkAEAAAAAHJV5ABx6dKlMXny5DjooIOipaUlfvnLX5Z7SyV37bXXRk1NTa913HHHFe7v7OyMBQsWxJgxY+KQQw6JuXPnxoYNG8q44+J59NFH4+yzz47m5uaoqamJe+65p9f9WZbF1VdfHRMmTIgRI0bEzJkz48UXX+x1zBtvvBHz5s2L+vr6aGhoiIsvvjg2b948gM+iON7uXFx00UV9fk9mz57d65hqOBepdYD8y3+E/L8ptfxH6AAdsIsO2EUHpNMB8r+b/O8i/+nkP0IHvNVg6YCKGyB+//vfj0WLFsU111wTTz31VEybNi1mzZoVr732Wrm3VnLvec97Yv369YX12GOPFe5buHBh/PSnP4277747HnnkkXj11VfjvPPOK+Nui2fLli0xbdq0WLp06R7v/8pXvhJf//rX49Zbb43ly5fHwQcfHLNmzYrOzs7CMfPmzYvnnnsu7r///rj33nvj0Ucfjfnz5w/UUyiatzsXERGzZ8/u9Xvyve99r9f9lX4uUu0A+Zd/+U83/xE6QAfogAgdkFoHyP9u8i//qeU/Qge81aDpgKzCnHrqqdmCBQsKX+/cuTNrbm7OlixZUsZdld4111yTTZs2bY/3bdy4MRs2bFh29913F257/vnns4jIWltbB2iHAyMish//+MeFr3t6erKmpqbsxhtvLNy2cePGrK6uLvve976XZVmW/epXv8oiInviiScKx/znf/5nVlNTk/32t78dsL0X2x+fiyzLsgsvvDD72Mc+lvs91XAuUuwA+d9F/neT/11SyH+W6YA36YDddMAuOiCdDpD/3eR/F/lPJ/9ZpgPeqpwdUFGvQNy+fXusWLEiZs6cWbittrY2Zs6cGa2trWXc2cB48cUXo7m5OY488siYN29erFu3LiIiVqxYETt27Oh1Xo477riYNGlS1Z+XtWvXRltbW6/nPnr06GhpaSk899bW1mhoaIj3ve99hWNmzpwZtbW1sXz58gHfc6k9/PDDMW7cuDj22GPjU5/6VLz++uuF+yr9XKTcAfLfl/z3Jf/VSwf0pQP60gHVSwf0Jv99yX/1kv++dEBfA9EBFTVA/N3vfhc7d+6M8ePH97p9/Pjx0dbWVqZdDYyWlpa4/fbb47777otbbrkl1q5dG3/6p38amzZtira2thg+fHg0NDT0+p4Uzsubz29vvxNtbW0xbty4XvcPHTo0Ghsbq+78zJ49O77zne/EsmXL4stf/nI88sgjMWfOnNi5c2dEVP65SLUD5H/P5L83+a9eOmDPdEBvOqB66YC+5L83+a9e8r9nOqC3geqAoUXdNSUzZ86cwr+nTp0aLS0tccQRR8QPfvCDGDFiRBl3xmBy/vnnF/59wgknxNSpU+Ooo46Khx9+OM4444wy7owDIf/sC/mvXjqAfaEDqpcO4O3If/WSf/bFQHVARb0CcezYsTFkyJA+nyq0YcOGaGpqKtOuyqOhoSGOOeaYWL16dTQ1NcX27dtj48aNvY5J4by8+fz29jvR1NTU5811u7u744033qj683PkkUfG2LFjY/Xq1RFR+edCB+wi/7vI/97Jf/XSAbvogL3TAdVLB8j/25H/6iX/u+iAvStVB1TUAHH48OFx8sknx7Jlywq39fT0xLJly2L69Oll3NnA27x5c6xZsyYmTJgQJ598cgwbNqzXeVm1alWsW7eu6s/LlClToqmpqddz7+joiOXLlxee+/Tp02Pjxo2xYsWKwjEPPvhg9PT0REtLy4DveSD95je/iddffz0mTJgQEZV/LnTALvK/i/zvnfxXLx2wiw7YOx1QvXSA/L8d+a9e8r+LDti7knVAfz/xpdzuuuuurK6uLrv99tuzX/3qV9n8+fOzhoaGrK2trdxbK6nPfe5z2cMPP5ytXbs2++///u9s5syZ2dixY7PXXnsty7Isu+yyy7JJkyZlDz74YPbkk09m06dPz6ZPn17mXRfHpk2bsqeffjp7+umns4jIvva1r2VPP/109vLLL2dZlmU33HBD1tDQkP3kJz/JnnnmmexjH/tYNmXKlGzbtm2Fx5g9e3Z24oknZsuXL88ee+yx7Oijj84uuOCCcj2l/ba3c7Fp06bs85//fNba2pqtXbs2e+CBB7KTTjopO/roo7POzs7CY1T6uUixA+Rf/rNM/rMszfxnmQ7QAbvoAB2QWgfI/27yL/+p5T/LdMBbDZYOqLgBYpZl2c0335xNmjQpGz58eHbqqadmjz/+eLm3VHIf//jHswkTJmTDhw/PDj/88OzjH/94tnr16sL927Ztyz796U9nhx56aDZy5Mjs3HPPzdavX1/GHRfPQw89lEVEn3XhhRdmWbbrI9yvuuqqbPz48VldXV12xhlnZKtWrer1GK+//np2wQUXZIccckhWX1+f/fVf/3W2adOmMjybA7O3c7F169bszDPPzA477LBs2LBh2RFHHJFdcsklff5PtRrORWodIP/yn2Xy/6bU8p9lOkAH7KIDdtEB6XSA/O8m/7vIfzr5zzId8FaDpQNqsizL9v31igAAAABASirqPRABAAAAgIFlgAgAAAAA5DJABAAAAAByGSACAAAAALkMEAEAAACAXAaIAAAAAEAuA0QAAAAAIJcBIgAAAACQywARAAAAAMhlgAgAAAAA5DJABAAAAAByGSACAAAAALkMEAEAAACAXAaIAAAAAEAuA0QAAAAAIJcBIgAAAACQywARAAAAAMhlgAgAAAAA5DJABAAAAAByGSACAAAAALkMEAEAAACAXAaIAAAAAEAuA0QAAAAAIJcBIgAAAACQywARAAAAAMhlgAgAAAAA5DJABAAAAAByGSACAAAAALkMEAEAAACAXAaIAAAAAEAuA0QAAAAAIJcBIgAAAACQywARAAAAAMhlgAgAAAAA5DJABAAAAAByGSACAAAAALkMEAEAAACAXAaIAAAAAEAuA0QAAAAAIJcBIgAAAACQywARAAAAAMhlgAgAAAAA5DJABAAAAAByGSACAAAAALkMEAEAAACAXAaIAAAAAEAuA0QAAAAAIJcBIgAAAACQywARAAAAAMhlgAgAAAAA5DJABAAAAAByGSACAAAAALkMEAEAAACAXAaIAAAAAEAuA0QAAAAAIJcBIgAAAACQywARAAAAAMhlgAgAAAAA5DJABAAAAAByGSACAAAAALkMEAEAAACAXAaIAAAAAEAuA0QAAAAAIJcBIgAAAACQywARAAAAAMhlgAgAAAAA5DJABAAAAAByGSACAAAAALkMEAEAAACAXAaIAAAAAEAuA0QAAAAAIJcBIgAAAACQq6wDxKVLl8bkyZPjoIMOipaWlvjlL39Zzu0AA0j+IW06ANIl/5A2HQCVqWwDxO9///uxaNGiuOaaa+Kpp56KadOmxaxZs+K1114r15aAASL/kDYdAOmSf0ibDoDKVZNlWVaOH9zS0hKnnHJKfOMb34iIiJ6enpg4cWJcccUV8fd///fl2BIwQOQf0qYDIF3yD2nTAVC5hpbjh27fvj1WrFgRixcvLtxWW1sbM2fOjNbW1j7Hd3V1RVdXV+Hrnp6eeOONN2LMmDFRU1MzIHuGapdlWWzatCmam5ujtrZ0L07ub/4jdACU2kDlP8I1AAxGrgEgbYO1A+QfSq8/+S/LAPF3v/td7Ny5M8aPH9/r9vHjx8evf/3rPscvWbIkrrvuuoHaHiTtlVdeiXe84x0le/z+5j9CB8BAKXX+I1wDwGDmGgDSNtg6QP5h4OxL/iviU5gXL14c7e3thbVu3bpybwmq1qhRo8q9hT50AAwM+Ye06QBI22DrAPmHgbMv+S/LKxDHjh0bQ4YMiQ0bNvS6fcOGDdHU1NTn+Lq6uqirqxuo7UHSSv3nAP3Nf4QOgIEyEH8O5BoABi/XAJC2wdYB8g8DZ1/yX5ZXIA4fPjxOPvnkWLZsWeG2np6eWLZsWUyfPr0cWwIGiPxD2nQApEv+IW06ACpcViZ33XVXVldXl91+++3Zr371q2z+/PlZQ0ND1tbW9rbf297enkWEZVklWO3t7YM6/1mmAyyrVGsg8p9lrgEsa7Au1wCWlfYa7B0g/5ZVurUv+S/LnzBHRHz84x+P//u//4urr7462tra4r3vfW/cd999fd5QtVq9853vjGHDhu33969Zsya2b9/e67bGxsYDOn8bN26M9evX97qttrY2jjnmmP1+OXtPT0+88MILkWXZfu9rX40YMSImT56839/f2dkZa9euLd6G+mno0KFx9NFH97l97dq10dnZWYYdlU7q+Y/QAaWgAypH6h0g/8Un/5Uj9fxH6IBS0AGVI/UOkP/ik/+BU5MNxP+iRdbR0RGjR48u9zYOyD/8wz/EmDFj9vv7v/zlL/d574gZM2bERz/60f1+zMcffzx+8IMf9LptxIgRcf3118eQIUP26zG3b98eV111VezYsWO/97WvJk+eHJ/5zGf2+/tfffXV+OpXv1rEHfVPfX19XHPNNX1K+qabbhrQNwxub2+P+vr6Aft5+0MH6IA90QEHTv4HhvwXn/wXhw4YGDqg+HRAcQz2DpB/+d8T+S+Ofcl/RXwKMwAAAABQHmX7E2b6WrlyZfzP//xPr9tGjRoV55577n6/dHjr1q3xwx/+sM9Lh88666w47LDD9nuv999/f7z66qu9bps8eXJ86EMf2u/HLIUsy+Luu++Obdu2ve2xg+3lwaRHBxSfDqBSyH/xyT+VRAcUnw6gUsh/8cl/aRggDiJtbW19imPMmDFx7rnn7vdj7tixI1auXNnn9hkzZuz3Y0bseu+FF154oc/tg7E4nn322di8eXO5twJvSwcUnw6gUsh/8ck/lUQHFJ8OoFLIf/HJf2kYIFL1hgwZsk/v3ZBlWfT09AzAjoCBpAMgXfIPadMBkC75Lz4DRKpaTU1NXHnllfv06U9tbW1x8803D8CugIGiAyBd8g9p0wGQLvkvDQNEqlpNTU0cdNBB+3RsXV1diXcDDDQdAOmSf0ibDoB0yX9pGCBSNbZt2xYvvvjiPh172GGHRUNDQ2k3BAwoHQDpkn9Imw6AdMn/wDFApGps2LAhbrnlln069pxzzonTTjutxDsCBpIOgHTJP6RNB0C65H/g1JZ7AwAAAADA4OUViIPICSecEGPGjOl124H+Pf6IESPiggsu6HP7H/+c/jr99NPj5JNP7nXboYceekCPeaDGjh0bH/7wh/fp2EmTJpV4N9B/OuDA6AAqmfwfGPmn0umAA6MDqGTyf2Dkf+AYIA4ihx9+eBx++OFFfczhw4fHKaecUtTHjIg49thji/6YB+qQQw4pyXOFgaIDDowOoJLJ/4GRfyqdDjgwOoBKJv8HRv4HjgFimfT09MTOnTuL+phZlh3QY+Z9xHlPT89+P+aBfG9/HejzH8i9DuY9MDB0QPHpACqF/Bef/FNJdEDx6QAqhfwXn/wPnJos77dlEOvo6IjRo0eXexsHZMSIEVFTU7Pf379t27Y+QR86dGgMHz58vx+zu7s7tm/f3uf2kSNH7vdjRkRs3br1gL5/X9XW1u7zR7XvSU9PT3R2dhZxR/1TU1MTI0aM6HN7Z2fngBZKe3t71NfXD9jP2x86QAfsiQ44cPI/MOS/+OS/OHTAwNABxacDimOwd4D8y/+eyH9x7Ev+vQKxTLZt21b0x+zu7o7u7u6iP+5ABf9A9fT0VMxe9yTLsoreP/2jA4pPB1Ap5L/45J9KogOKTwdQKeS/+OR/4FT0APGII46I2lofJA3F0NPTEy+//HK5t9EvOgCKQ/4hbToA0lZpHSD/UDz9yX9FDxAvvfTSA3qpKrBbZ2dnfPGLXyz3NvpFB0BxyD+kTQdA2iqtA+Qfiqc/+Te2BwAAAAByGSACAAAAALkMEAEAAACAXAaIAAAAAEAuA0QAAAAAIJcBIgAAAACQq+gDxCVLlsQpp5wSo0aNinHjxsU555wTq1at6nXMjBkzoqampte67LLLir0VYIDJP6RNB0DadACkS/6h+hV9gPjII4/EggUL4vHHH4/7778/duzYEWeeeWZs2bKl13GXXHJJrF+/vrC+8pWvFHsrwACTf0ibDoC06QBIl/xD9Rta7Ae87777en19++23x7hx42LFihVx2mmnFW4fOXJkNDU1FfvHA2Uk/5A2HQBp0wGQLvmH6lfy90Bsb2+PiIjGxsZet99xxx0xduzYOP7442Px4sWxdevWUm8FGGDyD2nTAZA2HQDpkn+oPkV/BeJb9fT0xGc/+9n4wAc+EMcff3zh9k984hNxxBFHRHNzczzzzDNx5ZVXxqpVq+JHP/rRHh+nq6srurq6Cl93dHSUcttAERQr/xE6ACqRawBImw6AdMk/VKeSDhAXLFgQzz77bDz22GO9bp8/f37h3yeccEJMmDAhzjjjjFizZk0cddRRfR5nyZIlcd1115Vyq0CRFSv/EToAKpFrAEibDoB0yT9Up5L9CfPll18e9957bzz00EPxjne8Y6/HtrS0RETE6tWr93j/4sWLo729vbBeeeWVou8XKJ5i5j9CB0ClcQ0AadMBkC75h+pV9FcgZlkWV1xxRfz4xz+Ohx9+OKZMmfK237Ny5cqIiJgwYcIe76+rq4u6urpibhMogVLkP0IHQKVwDQBp0wGQLvmH6lf0AeKCBQvizjvvjJ/85CcxatSoaGtri4iI0aNHx4gRI2LNmjVx5513xllnnRVjxoyJZ555JhYuXBinnXZaTJ06tdjbAQaQ/EPadACkTQdAuuQfql/RB4i33HJLRETMmDGj1+233XZbXHTRRTF8+PB44IEH4qabbootW7bExIkTY+7cufGlL32p2FsBBpj8Q9p0AKRNB0C65B+qX0n+hHlvJk6cGI888kixfywwCMg/pE0HQNp0AKRL/qH6lexDVAAAAACAylf0VyAONl1dXfH73/++3NuAsjn00EOTfvNhHUDqUu4A+Sd1Kec/QgdAyh0g/6SuFPmv+gHi2rVr45vf/Ga5twFlc+mll8axxx5b7m2UjQ4gdSl3gPyTupTzH6EDIOUOkH9SV4r8+xNmAAAAACCXASIAAAAAkMsAEQAAAADIZYAIAAAAAOQyQAQAAAAAchkgAgAAAAC5DBABAAAAgFwGiAAAAABALgNEAAAAACCXASIAAAAAkMsAEQAAAADIZYAIAAAAAOQyQAQAAAAAchkgAgAAAAC5DBABAAAAgFwGiAAAAABALgNEAAAAACCXASIAAAAAkMsAEQAAAADIZYAIAAAAAOQq+gDx2muvjZqaml7ruOOOK9zf2dkZCxYsiDFjxsQhhxwSc+fOjQ0bNhR7G0AZyD+kTQdA2nQApEv+ofqV5BWI73nPe2L9+vWF9dhjjxXuW7hwYfz0pz+Nu+++Ox555JF49dVX47zzzivFNoAykH9Imw6AtOkASJf8Q3UbWpIHHTo0mpqa+tze3t4e3/rWt+LOO++MP/uzP4uIiNtuuy3e9a53xeOPPx7vf//7S7EdYADJP6RNB0DadACkS/6hupXkFYgvvvhiNDc3x5FHHhnz5s2LdevWRUTEihUrYseOHTFz5szCsccdd1xMmjQpWltbcx+vq6srOjo6ei1gcCp2/iN0AFQS1wCQNh0A6ZJ/qG5FHyC2tLTE7bffHvfdd1/ccsstsXbt2vjTP/3T2LRpU7S1tcXw4cOjoaGh1/eMHz8+2trach9zyZIlMXr06MKaOHFisbcNFEEp8h+hA6BSuAaAtOkASJf8Q/Ur+p8wz5kzp/DvqVOnRktLSxxxxBHxgx/8IEaMGLFfj7l48eJYtGhR4euOjg7lAYNQKfIfoQOgUrgGgLTpAEiX/EP1K8mfML9VQ0NDHHPMMbF69epoamqK7du3x8aNG3sds2HDhj2+V8Kb6urqor6+vtcCBr9i5D9CB0Clcg0AadMBkC75h+pT8gHi5s2bY82aNTFhwoQ4+eSTY9iwYbFs2bLC/atWrYp169bF9OnTS70VYIDJP6RNB0DadACkS/6h+hT9T5g///nPx9lnnx1HHHFEvPrqq3HNNdfEkCFD4oILLojRo0fHxRdfHIsWLYrGxsaor6+PK664IqZPn+6Tl6AKyD+kTQdA2nQApEv+ofoVfYD4m9/8Ji644IJ4/fXX47DDDosPfvCD8fjjj8dhhx0WERH//M//HLW1tTF37tzo6uqKWbNmxb/8y78UextAGcg/pE0HQNp0AKRL/qH6FX2AeNddd+31/oMOOiiWLl0aS5cuLfaPBspM/iFtOgDSpgMgXfIP1a/k74EIAAAAAFSuor8CcbB59+jRceupp5Z7G1A2naNHR0+5N1FGOoDUpdwB8k/qUs5/hA6AlDtA/kldKfJf9QPE+mHD4t2NjeXeBpTNc8OGRXu5N1FGOoDUpdwB8k/qUs5/hA6AlDtA/kldKfLvT5gBAAAAgFwGiAAAAABALgNEAAAAACCXASIAAAAAkMsAEQAAAADIZYAIAAAAAOQaWu4NlFpWtzN6mreUextQPnU7y72DstIBJC/hDpB/kpdw/iN0AKTcAfJP8kqQ/6ofIMaQLGJkusUJUZuVewflpQNIXcodIP+kLuX8R+gASLkD5J/UlSD//oQZAAAAAMhlgAgAAAAA5DJABAAAAAByGSACAAAAALkMEAEAAACAXAaIAAAAAECuoeXeQKntHNITm0Z0lnsbUDbdQ3rKvYWy0gGkLuUOkH9Sl3L+I3QApNwB8k/qSpH/qh8g9tRksWNYusUJWU1W7i2UlQ4gdSl3gPyTupTzH6EDIOUOkH9SV4r8+xNmAAAAACCXASIAAAAAkMsAEQAAAADIVfQB4uTJk6OmpqbPWrBgQUREzJgxo899l112WbG3AZSJDoB0yT+kTQdAuuQfql/RP0TliSeeiJ07dxa+fvbZZ+PDH/5w/MVf/EXhtksuuSSuv/76wtcjR44s9jaAMtEBkC75h7TpAEiX/EP1K/oA8bDDDuv19Q033BBHHXVUfOhDHyrcNnLkyGhqair2jwYGAR0A6ZJ/SJsOgHTJP1S/og8Q32r79u3x3e9+NxYtWhQ1NTWF2++444747ne/G01NTXH22WfHVVddVbL/+rCzLotNzTtK8thQCXbuyCKK/wnu+0QHQPmVqwPkH8rPNYAOIG2uAeSfdJUi/yUdIN5zzz2xcePGuOiiiwq3feITn4gjjjgimpub45lnnokrr7wyVq1aFT/60Y9yH6erqyu6uroKX3d0dOzzHnqGZrGjvkxXTjAI9LRHRJn+v1MHQPmVqwPkH8rPNYAOIG2uAeSfdJUi/yUdIH7rW9+KOXPmRHNzc+G2+fPnF/59wgknxIQJE+KMM86INWvWxFFHHbXHx1myZElcd911pdwqUAI6ANIl/5A2HQDpkn+oTkX/FOY3vfzyy/HAAw/E3/7t3+71uJaWloiIWL16de4xixcvjvb29sJ65ZVXirpXoPh0AKRL/iFtOgDSJf9QvUr2CsTbbrstxo0bFx/5yEf2etzKlSsjImLChAm5x9TV1UVdXV0xtweUmA6AdMk/pE0HQLrkH6pXSQaIPT09cdttt8WFF14YQ4fu/hFr1qyJO++8M84666wYM2ZMPPPMM7Fw4cI47bTTYurUqaXYClAGOgDSJf+QNh0A6ZJ/qG4lGSA+8MADsW7duvibv/mbXrcPHz48Hnjggbjppptiy5YtMXHixJg7d2586UtfKsU2gDLRAZAu+Ye06QBIl/xDdSvJAPHMM8+MLOv7iUcTJ06MRx55pBQ/EhhEdACkS/4hbToA0iX/UN1K+inMg8HGGB7P9Ywp9zagbA6PYXFwuTdRRjqA1KXcAfJP6lLOf4QOgJQ7QP5JXSnyX/UDxG0xJF5KtjYhYkw2JOkE6ABSl3IHyD+pSzn/EToAUu4A+Sd1pch/bZEfDwAAAACoIgaIAAAAAEAuA0QAAAAAIJcBIgAAAACQywARAAAAAMhlgAgAAAAA5Bpa7g2UWtY+LrqfP7vc24CyyZq3R4zMyr2NstEBpC7lDpB/Updy/iN0AKTcAfJP6kqR/+ofIG6tj57/fXe5twFlkx36XMTI9nJvo2x0AKlLuQPkn9SlnP8IHQApd4D8k7pS5N+fMAMAAAAAuQwQAQAAAIBcBogAAAAAQC4DRAAAAAAglwEiAAAAAJDLABEAAAAAyDW03Bsota2bX4oXfvWf5d4GlM0Jx74rYkxDubdRNjqA1KXcAfJP6lLOf4QOgJQ7QP5JXSnyX/UDxM7OtvjNurvLvQ0om87OSyOiodzbKBsdQOpS7gD5J3Up5z9CB0DKHSD/pK4U+fcnzAAAAABALgNEAAAAACCXASIAAAAAkMsAEQAAAADIZYAIAAAAAOTq9wDx0UcfjbPPPjuam5ujpqYm7rnnnl73Z1kWV199dUyYMCFGjBgRM2fOjBdffLHXMW+88UbMmzcv6uvro6GhIS6++OLYvHnzAT0RoPTkH9KmAyBd8g9p0wFAvweIW7ZsiWnTpsXSpUv3eP9XvvKV+PrXvx633nprLF++PA4++OCYNWtWdHZ2Fo6ZN29ePPfcc3H//ffHvffeG48++mjMnz9//58FMCDkH9KmAyBd8g9p0wHA0P5+w5w5c2LOnDl7vC/LsrjpppviS1/6UnzsYx+LiIjvfOc7MX78+Ljnnnvi/PPPj+effz7uu+++eOKJJ+J973tfRETcfPPNcdZZZ8VXv/rVaG5uPoCnA5SS/EPadACkS/4hbToAKOp7IK5duzba2tpi5syZhdtGjx4dLS0t0draGhERra2t0dDQUCiNiIiZM2dGbW1tLF++fI+P29XVFR0dHb0WMLiUKv8ROgAqgWsASJdrAEibawBIQ1EHiG1tbRERMX78+F63jx8/vnBfW1tbjBs3rtf9Q4cOjcbGxsIxf2zJkiUxevTowpo4cWIxtw0UQanyH6EDoBK4BoB0uQaAtLkGgDRUxKcwL168ONrb2wvrlVdeKfeWgAGkAyBd8g9p0wGQLvmHwaWoA8SmpqaIiNiwYUOv2zds2FC4r6mpKV577bVe93d3d8cbb7xROOaP1dXVRX19fa8FDC6lyn+EDoBK4BoA0uUaANLmGgDSUNQB4pQpU6KpqSmWLVtWuK2joyOWL18e06dPj4iI6dOnx8aNG2PFihWFYx588MHo6emJlpaWYm4HGEDyD2nTAZAu+Ye06QBIQ78/hXnz5s2xevXqwtdr166NlStXRmNjY0yaNCk++9nPxj/+4z/G0UcfHVOmTImrrroqmpub45xzzomIiHe9610xe/bsuOSSS+LWW2+NHTt2xOWXXx7nn3++T16CQU7+IW06ANIl/5A2HQD0e4D45JNPxumnn174etGiRRERceGFF8btt98eX/jCF2LLli0xf/782LhxY3zwgx+M++67Lw466KDC99xxxx1x+eWXxxlnnBG1tbUxd+7c+PrXv16EpwOUkvxD2nQApEv+IW06AOj3AHHGjBmRZVnu/TU1NXH99dfH9ddfn3tMY2Nj3Hnnnf390UCZyT+kTQdAuuQf0qYDgIr4FGYAAAAAoDwMEAEAAACAXAaIAAAAAEAuA0QAAAAAIJcBIgAAAACQywARAAAAAMhlgAgAAAAA5DJABAAAAAByGSACAAAAALkMEAEAAACAXAaIAAAAAEAuA0QAAAAAIJcBIgAAAACQywARAAAAAMhlgAgAAAAA5DJABAAAAAByGSACAAAAALkMEAEAAACAXAaIAAAAAEAuA0QAAAAAIJcBIgAAAACQywARAAAAAMjV7wHio48+GmeffXY0NzdHTU1N3HPPPYX7duzYEVdeeWWccMIJcfDBB0dzc3P81V/9Vbz66qu9HmPy5MlRU1PTa91www0H/GSA0pJ/SJsOgHTJP6RNBwD9HiBu2bIlpk2bFkuXLu1z39atW+Opp56Kq666Kp566qn40Y9+FKtWrYqPfvSjfY69/vrrY/369YV1xRVX7N8zAAaM/EPadACkS/4hbToAGNrfb5gzZ07MmTNnj/eNHj067r///l63feMb34hTTz011q1bF5MmTSrcPmrUqGhqaurvjwfKSP4hbToA0iX/kDYdAJT8PRDb29ujpqYmGhoaet1+ww03xJgxY+LEE0+MG2+8Mbq7u3Mfo6urKzo6OnotYPArRv4jdABUKtcAkC7XAJA21wBQffr9CsT+6OzsjCuvvDIuuOCCqK+vL9z+mc98Jk466aRobGyMX/ziF7F48eJYv359fO1rX9vj4yxZsiSuu+66Um4VKLJi5T9CB0Alcg0A6XINAGlzDQDVqWQDxB07dsRf/uVfRpZlccstt/S6b9GiRYV/T506NYYPHx6XXnppLFmyJOrq6vo81uLFi3t9T0dHR0ycOLFUWwcOUDHzH6EDoNK4BoB0uQaAtLkGgOpVkgHim6Xx8ssvx4MPPtjrvzrsSUtLS3R3d8dLL70Uxx57bJ/76+rqci8qgMGl2PmP0AFQSVwDQLpcA0DaXANAdSv6APHN0njxxRfjoYceijFjxrzt96xcuTJqa2tj3Lhxxd4OMIDkH9KmAyBd8g9p0wFQ/fo9QNy8eXOsXr268PXatWtj5cqV0djYGBMmTIg///M/j6eeeiruvffe2LlzZ7S1tUVERGNjYwwfPjxaW1tj+fLlcfrpp8eoUaOitbU1Fi5cGJ/85Cfj0EMPLd4zA4pO/iFtOgDSJf+QNh0A9HuA+OSTT8bpp59e+PrN9yS48MIL49prr41///d/j4iI9773vb2+76GHHooZM2ZEXV1d3HXXXXHttddGV1dXTJkyJRYuXNjrvQ2AwUn+IW06ANIl/5A2HQD0e4A4Y8aMyLIs9/693RcRcdJJJ8Xjjz/e3x8LDALyD2nTAZAu+Ye06QCgttwbAAAAAAAGLwNEAAAAACCXASIAAAAAkMsAEQAAAADIZYAIAAAAAOQyQAQAAAAAchkgAgAAAAC5DBABAAAAgFxDy70BBofPHHtsTD7kkNja3R1X/c//RFbuDQEAAAAwKBggEhERxzc0xNRDD4327dujJsIAEQAAAICI8CfMAAAAAMBeGCACAAAAALkMEAEAAACAXN4DkYiIWPn738fG7dtjy86d3v8Qqtiw2tp4/9ixERGxftu2WL1pU5l3BAAAwGBngEhERPzLCy+UewvAABg1dGh8+cQTo7amJn78yivx5eeeK/eWAAAAGOT8CTMAAAAAkMsAEQAAAADIZYAIAAAAAOTyHogACckiYntPT9RERHdPT7m3A5RIbUQMrd3134l39PT4gDQAAA6IASJAQn6/fXvMefDBiIjozowUoFqdM3FiXH7ssRER8alf/jJWdXSUeUcAAFQyA0SAxGzbubPcWwBKbGhtbYwcuusyz/vVAABwoFxTAgAAAAC5+j1AfPTRR+Pss8+O5ubmqKmpiXvuuafX/RdddFHU1NT0WrNnz+51zBtvvBHz5s2L+vr6aGhoiIsvvjg2b958QE8EKD35h7TpAEiX/EPadADQ7wHili1bYtq0abF06dLcY2bPnh3r168vrO9973u97p83b14899xzcf/998e9994bjz76aMyfP7//uwcGlPxD2nQApEv+IW06AOj3eyDOmTMn5syZs9dj6urqoqmpaY/3Pf/883HffffFE088Ee973/siIuLmm2+Os846K7761a9Gc3Nzf7cEDBD5h7TpgMrx+P/9X1y1fXtERPx227Yy74ZqIP+D16ePOSaaDjoo2nfsiH96/vlyb4cqpQOAkrwH4sMPPxzjxo2LY489Nj71qU/F66+/XrivtbU1GhoaCqURETFz5syora2N5cuXl2I7wACSf0ibDhgc1m3dGvevXx/3r18fHTt2lHs7JEL+y2P62LFxZnNzfGj8+HJvhcTpAKhuRf8U5tmzZ8d5550XU6ZMiTVr1sQXv/jFmDNnTrS2tsaQIUOira0txo0b13sTQ4dGY2NjtLW17fExu7q6oqurq/B1R0dHsbcNFEEp8h+hA6BSuAaAdLkGgLS5BoDqV/QB4vnnn1/49wknnBBTp06No446Kh5++OE444wz9usxlyxZEtddd12xtgiUSCnyH6EDoFK4BoB0uQaAtLkGgOpXkj9hfqsjjzwyxo4dG6tXr46IiKampnjttdd6HdPd3R1vvPFG7vslLF68ONrb2wvrlVdeKfW2gSIoRv4jdABUKtcAkC7XAJA21wBQfYr+CsQ/9pvf/CZef/31mDBhQkRETJ8+PTZu3BgrVqyIk08+OSIiHnzwwejp6YmWlpY9PkZdXV3U1dWVeqtAkRUj/xE6ACqVawBIl2uAgfN8R0ds6u6O3//hg5NgMHANUFzDa2vjPaNHR0TEhs7OeNUHpFEG/R4gbt68ufBfESIi1q5dGytXrozGxsZobGyM6667LubOnRtNTU2xZs2a+MIXvhDvfOc7Y9asWRER8a53vStmz54dl1xySdx6662xY8eOuPzyy+P888/3yUswyMk/pE0HQLrkf/D6/z77bLm3QAJ0QHmNqauLfzn11KipqYn/3//+byx94YVyb4kE9ftPmJ988sk48cQT48QTT4yIiEWLFsWJJ54YV199dQwZMiSeeeaZ+OhHPxrHHHNMXHzxxXHyySfHz3/+817/5eCOO+6I4447Ls4444w466yz4oMf/GB885vfLN6zAkpC/iFtOgDSJf+QNh0A9PsViDNmzIgsy3Lv/6//+q+3fYzGxsa48847+/ujgTKTf0ibDoB0yT+kTQcAJf8QFQAAAACgcpX8Q1QAAAAA2H89ERFZFvmvA4XSMkAEAAAAGKQ2bNsWH3nwwYiI6OzpKfNuSJUBIgAAAMAg1RMRG3fsKPc2SJz3QAQAAAAAchkgAgAAAAC5DBABAAAAgFwGiAAAAABALgNEAAAAACCXASIAAAAAkMsAEQAAAADIZYAIAAAAAOQyQAQAAAAAchkgAgAAAAC5DBABAAAAgFwGiAAAAABALgNEAAAAACCXASIAAAAAkMsAEQAAAADIZYAIAAAAAOQyQAQAAAAAchkgAgAAAAC5DBABAAAAgFz9HiA++uijcfbZZ0dzc3PU1NTEPffc0+v+mpqaPa4bb7yxcMzkyZP73H/DDTcc8JMBSkv+IW06ANIl/5A2HQD0e4C4ZcuWmDZtWixdunSP969fv77X+va3vx01NTUxd+7cXsddf/31vY674oor9u8ZAANG/iFtOgDSJf+QNh0ADO3vN8yZMyfmzJmTe39TU1Ovr3/yk5/E6aefHkceeWSv20eNGtXnWGBwk39Imw6AdMk/pE0HACV9D8QNGzbEf/zHf8TFF1/c574bbrghxowZEyeeeGLceOON0d3dnfs4XV1d0dHR0WsBg1ux8h+hA6ASuQaAdLkGgLS5BoDq1O9XIPbHv/3bv8WoUaPivPPO63X7Zz7zmTjppJOisbExfvGLX8TixYtj/fr18bWvfW2Pj7NkyZK47rrrSrlVoMiKlf8IHQCVyDUApMs1AKTNNQBUp5IOEL/97W/HvHnz4qCDDup1+6JFiwr/njp1agwfPjwuvfTSWLJkSdTV1fV5nMWLF/f6no6Ojpg4cWLpNg4csGLlP0IHQCVyDQDpcg0AaXMNANWpZAPEn//857Fq1ar4/ve//7bHtrS0RHd3d7z00ktx7LHH9rm/rq4u96ICGHyKmf8IHQCVxjUApMs1AKTNNQBUr5K9B+K3vvWtOPnkk2PatGlve+zKlSujtrY2xo0bV6rtAANI/iFtOgDSJf+QNh0A1avfr0DcvHlzrF69uvD12rVrY+XKldHY2BiTJk2KiF0vLb777rvjn/7pn/p8f2trayxfvjxOP/30GDVqVLS2tsbChQvjk5/8ZBx66KEH8FSAUpN/SJsOgHTJP6RNBwD9HiA++eSTcfrppxe+fvM9CS688MK4/fbbIyLirrvuiizL4oILLujz/XV1dXHXXXfFtddeG11dXTFlypRYuHBhr/c2AAYn+Ye06QBIl/xD2nQA0O8B4owZMyLLsr0eM3/+/Jg/f/4e7zvppJPi8ccf7++PBQYB+Ye06QBIl/xD2nQAULL3QAQAAAAAKp8BIgAAAACQywARAAAAAMhlgAgAAAAA5DJABAAAAAByGSACAAAAALkMEAEAAACAXAaIAAAAAEAuA0QAAAAAIJcBIgAAAACQa2i5N3AgOmt6Imp69nrM9ppsgHZDOR08dGgcNGRIUR9zZ09PbNyxo6iPWQ5Dd+yIYV1db3tc9z4cM9joAN6kA/LtSwfIP5VM/vO5BtABKdAB+aq1A+S/eowaOjSGFzm/3T090V4F+T1Qpch/RQ8QHx61NYaO2HtxvD6yc4B2Qzl95thj4+x3vKOoj7l28+aY99//XdTHLIdjnnkm3vfqq2973Jbu7gHYTXHpAN6kA/LtSwfIP5VM/vO5BtABKdAB+aq1A+S/elz5nvfEnzU1FfUxn2tvj0sef7yoj1mJSpH/ih4gRs0fFkREbU1xfxmq5VdrX2NSkc9XB/AWOmDP9iUmFflc5Z+3kP89cw1AKnTAnlVtB8h/1aipqZHfEilF/r0HIgAAAACQywARAAAAAMhlgAgAAAAA5Krs90CEP/jO//5v/PS3vy3qY3bu3FnUxwNKRwdAuuQf0qYDoHLd+sIL8b2XXirqY26tsA8FqiQGiFSF327bFr/dtq3c2wDKRAdAuuQf0qYDoHK9snVrvLJ1a7m3wT4yQIQqt7m7O36/ffvbHtefj28HKse+dID8Q3VyDQBp0wGQrlLk3wARqtw/rFy5Tx/NnpV8J0A57EsHyD9UJ9cAkDYdAOkqRf4reoC48p++EzW1e/8cmO6tXs5O2rKo3osCHQBvr1o7QP7h7VVr/iN0AOyLau0A+Ye3V4r8V/QAseN/f1PuLQBlpAMgXfIPadMBkC75h/LY+9j+jyxZsiROOeWUGDVqVIwbNy7OOeecWLVqVa9jOjs7Y8GCBTFmzJg45JBDYu7cubFhw4Zex6xbty4+8pGPxMiRI2PcuHHxd3/3d9HtfRdg0NMBkC75h7TpAEiX/AMREZH1w6xZs7Lbbrste/bZZ7OVK1dmZ511VjZp0qRs8+bNhWMuu+yybOLEidmyZcuyJ598Mnv/+9+f/cmf/Enh/u7u7uz444/PZs6cmT399NPZz372s2zs2LHZ4sWL93kf7e3tb74a07KsIq/29nYdYFmJLvm3rLSXDrCstFdeB8i/ZVX/2ts1wJv6NUD8Y6+99loWEdkjjzySZVmWbdy4MRs2bFh29913F455/vnns4jIWltbsyzLsp/97GdZbW1t1tbWVjjmlltuyerr67Ourq59+rmKw7JKt/alOHSAZVXnkn/LSnvpAMtKe+1rB8i/ZVXf2pf89+tPmP9Ye3t7REQ0NjZGRMSKFStix44dMXPmzMIxxx13XEyaNClaW1sjIqK1tTVOOOGEGD9+fOGYWbNmRUdHRzz33HMHsh1ggOkASJf8Q9p0AKRL/iFN+/0hKj09PfHZz342PvCBD8Txxx8fERFtbW0xfPjwaGho6HXs+PHjo62trXDMW0vjzfvfvG9Purq6oqurq/B1R0fH/m4bKBIdAOmSf0ibDoB0yT+ka79fgbhgwYJ49tln46677irmfvZoyZIlMXr06MKaOHFiyX8msHc6ANIl/5A2HQDpkn9I134NEC+//PK4995746GHHop3vOMdhdubmppi+/btsXHjxl7Hb9iwIZqamgrH/PGnMb359ZvH/LHFixdHe3t7Yb3yyiv7s22gSHQApEv+IW06ANIl/5C4fXq30j/o6enJFixYkDU3N2cvvPBCn/vffPPUH/7wh4Xbfv3rX2cRfd88dcOGDYVj/vVf/zWrr6/POjs792kf3jzVskq39vbmqTrAsqp7yb9lpb10gGWlvfI6QP4tq/pX0T+F+VOf+lQ2evTo7OGHH87Wr19fWFu3bi0cc9lll2WTJk3KHnzwwezJJ5/Mpk+fnk2fPr1w/5sf337mmWdmK1euzO67777ssMMO8/HtljVI1t6KQwdYVnUv+bestJcOsKy0V14HyL9lVf8q+gAx7wfddttthWO2bduWffrTn84OPfTQbOTIkdm5556brV+/vtfjvPTSS9mcOXOyESNGZGPHjs0+97nPZTt27NjnfSgOyyrd2ltx5H2PDrCs6ljyb1lpLx1gWWmvvA7IO17+Lat61r4MEGv+UAgVpaOjI0aPHl3ubUBVam9vj/r6+nJvY690AJSG/EPadACkbbB3gPxD6exL/vf7U5gBAAAAgOpngAgAAAAA5DJABAAAAAByGSACAAAAALkMEAEAAACAXBU5QKzAD46GilEJ+aqEPUIlqoRsVcIeoVJVQr4qYY9QqQZ7vgb7/qCS7Uu+KnKAuGnTpnJvAapWJeTr9ddfL/cWoCpVQv4rYY9QqSohX64BoHQGewcM9v1BJduXfNVkFTjG7+npiVWrVsW73/3ueOWVV6K+vr7cWyqrjo6OmDhxYvLnwnnYbX/ORZZlsWnTpmhubo7a2sH93xY2btwYhx56aKxbty5Gjx5d7u2Uld/73ZyL3fp7Liop/64BevN7v4vzsJtrgHT4vd/NuditmjvANUBvfu93cy52KXX+hxZjkwOttrY2Dj/88IiIqK+vT/oX5K2ci12ch936ey4q5UL8zWIbPXq0/63/wO/9bs7Fbv05F5WUf9cAfTkXuzgPu7kGSIff+92ci92qsQNcA+yZc7Gbc7FLqfI/eP/zAgAAAABQdgaIAAAAAECuih0g1tXVxTXXXBN1dXXl3krZORe7OA+7Vfu5qPbn1x/OxW7OxW7Vfi6q/fn1h3Oxi/OwW7Wfi2p/fv3hXOzmXOxW7eei2p9ffzgXuzkXu5T6PFTkh6gAAAAAAAOjYl+BCAAAAACUngEiAAAAAJDLABEAAAAAyGWACAAAAADkqsgB4tKlS2Py5Mlx0EEHRUtLS/zyl78s95ZK7tprr42amppe67jjjivc39nZGQsWLIgxY8bEIYccEnPnzo0NGzaUccfF8+ijj8bZZ58dzc3NUVNTE/fcc0+v+7Msi6uvvjomTJgQI0aMiJkzZ8aLL77Y65g33ngj5s2bF/X19dHQ0BAXX3xxbN68eQCfRXG83bm46KKL+vyezJ49u9cx1XAuUusA+Zf/CPl/U2r5j9ABOmAXHbCLDkinA+R/N/nfRf7TyX+EDnirwdIBFTdA/P73vx+LFi2Ka665Jp566qmYNm1azJo1K1577bVyb63k3vOe98T69esL67HHHivct3DhwvjpT38ad999dzzyyCPx6quvxnnnnVfG3RbPli1bYtq0abF06dI93v+Vr3wlvv71r8ett94ay5cvj4MPPjhmzZoVnZ2dhWPmzZsXzz33XNx///1x7733xqOPPhrz588fqKdQNG93LiIiZs+e3ev35Hvf+16v+yv9XKTaAfIv//Kfbv4jdIAO0AEROiC1DpD/3eRf/lPLf4QOeKtB0wFZhTn11FOzBQsWFL7euXNn1tzcnC1ZsqSMuyq9a665Jps2bdoe79u4cWM2bNiw7O677y7c9vzzz2cRkbW2tg7QDgdGRGQ//vGPC1/39PRkTU1N2Y033li4bePGjVldXV32ve99L8uyLPvVr36VRUT2xBNPFI75z//8z6ympib77W9/O2B7L7Y/PhdZlmUXXnhh9rGPfSz3e6rhXKTYAfK/i/zvJv+7pJD/LNMBb9IBu+mAXXRAOh0g/7vJ/y7yn07+s0wHvFU5O6CiXoG4ffv2WLFiRcycObNwW21tbcycOTNaW1vLuLOB8eKLL0Zzc3MceeSRMW/evFi3bl1ERKxYsSJ27NjR67wcd9xxMWnSpKo/L2vXro22trZez3306NHR0tJSeO6tra3R0NAQ73vf+wrHzJw5M2pra2P58uUDvudSe/jhh2PcuHFx7LHHxqc+9al4/fXXC/dV+rlIuQPkvy/570v+q5cO6EsH9KUDqpcO6E3++5L/6iX/femAvgaiAypqgPi73/0udu7cGePHj+91+/jx46Otra1MuxoYLS0tcfvtt8d9990Xt9xyS6xduzb+9E//NDZt2hRtbW0xfPjwaGho6PU9KZyXN5/f3n4n2traYty4cb3uHzp0aDQ2Nlbd+Zk9e3Z85zvfiWXLlsWXv/zleOSRR2LOnDmxc+fOiKj8c5FqB8j/nsl/b/JfvXTAnumA3nRA9dIBfcl/b/JfveR/z3RAbwPVAUOLumtKZs6cOYV/T506NVpaWuKII46IH/zgBzFixIgy7ozB5Pzzzy/8+4QTToipU6fGUUcdFQ8//HCcccYZZdwZB0L+2RfyX710APtCB1QvHcDbkf/qJf/si4HqgIp6BeLYsWNjyJAhfT5VaMOGDdHU1FSmXZVHQ0NDHHPMMbF69epoamqK7du3x8aNG3sdk8J5efP57e13oqmpqc+b63Z3d8cbb7xR9efnyCOPjLFjx8bq1asjovLPhQ7YRf53kf+9k//qpQN20QF7pwOqlw6Q/7cj/9VL/nfRAXtXqg6oqAHi8OHD4+STT45ly5YVbuvp6Ylly5bF9OnTy7izgbd58+ZYs2ZNTJgwIU4++eQYNmxYr/OyatWqWLduXdWflylTpkRTU1Ov597R0RHLly8vPPfp06fHxo0bY8WKFYVjHnzwwejp6YmWlpYB3/NA+s1vfhOvv/56TJgwISIq/1zogF3kfxf53zv5r146YBcdsHc6oHrpAPl/O/JfveR/Fx2wdyXrgP5+4ku53XXXXVldXV12++23Z7/61a+y+fPnZw0NDVlbW1u5t1ZSn/vc57KHH344W7t2bfbf//3f2cyZM7OxY8dmr732WpZlWXbZZZdlkyZNyh588MHsySefzKZPn55Nnz69zLsujk2bNmVPP/109vTTT2cRkX3ta1/Lnn766ezll1/OsizLbrjhhqyhoSH7yU9+kj3zzDPZxz72sWzKlCnZtm3bCo8xe/bs7MQTT8yWL1+ePfbYY9nRRx+dXXDBBeV6Svttb+di06ZN2ec///mstbU1W7t2bfbAAw9kJ510Unb00UdnnZ2dhceo9HORYgfIv/xnmfxnWZr5zzIdoAN20QE6ILUOkP/d5F/+U8t/lumAtxosHVBxA8Qsy7Kbb745mzRpUjZ8+PDs1FNPzR5//PFyb6nkPv7xj2cTJkzIhg8fnh1++OHZxz/+8Wz16tWF+7dt25Z9+tOfzg499NBs5MiR2bnnnputX7++jDsunoceeiiLiD7rwgsvzLJs10e4X3XVVdn48eOzurq67IwzzshWrVrV6zFef/317IILLsgOOeSQrL6+Pvvrv/7rbNOmTWV4Ngdmb+di69at2Zlnnpkddthh2bBhw7Ijjjgiu+SSS/r8n2o1nIvUOkD+5T/L5P9NqeU/y3SADthFB+yiA9LpAPnfTf53kf908p9lOuCtBksH1GRZlu376xUBAAAAgJRU1HsgAgAAAAADywARAAAAAMhlgAgAAAAA5DJABAAAAAByGSACAAAAALkMEAEAAACAXAaIAAAAAEAuA0QAAAAAIJcBIgAAAACQywARAAAAAMhlgAgAAAAA5DJABAAAAABy/b+VsdhADUlHeAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1600x900 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make(ENV_NAME, render_mode=\"rgb_array\")\n",
    "env.reset()\n",
    "\n",
    "n_cols = 5\n",
    "n_rows = 2\n",
    "fig = plt.figure(figsize=(16, 9))\n",
    "\n",
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        ax = fig.add_subplot(n_rows, n_cols, row * n_cols + col + 1)\n",
    "        ax.imshow(env.render())\n",
    "        env.step(env.action_space.sample())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YsPtiUtFIZzu"
   },
   "source": [
    "**About the game:** You have 5 lives and get points for breaking the wall. Higher bricks cost more than the lower ones. There are 4 actions: start game (should be called at the beginning and after each life is lost), move left, move right and do nothing. There are some common wrappers used for Atari environments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kbQ6PfCOIZzu"
   },
   "source": [
    "**Let's take a look at action meanings:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8EpIJTIKIZzu",
    "outputId": "18207d53-00f5-4a8b-a5a6-f7c2172bbed2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NOOP', 'FIRE', 'RIGHT', 'LEFT']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.unwrapped.get_action_meanings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eX1iuuvpIZzu"
   },
   "source": [
    "1. NOOP stands for the action of doing nothing\n",
    "2. Right and Left move the platform to the corresponding direction\n",
    "3. Fire releases the ball in the beginning of a life\n",
    "\n",
    "In this assignment we will wrap the environment to execute the \"Fire\" action in the beginning of a life automatically. It will turn the \"FIRE\" action into another \"NOOP\".  \n",
    "Also, we will wrap the environment to make an episode last for 1 life instead of 5 ones.  \n",
    "These transforms are claimed as non-recommended in the paper [5] but it was done in the original paper [1] and it will help the training to converge faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hLNt1fbnsoUB"
   },
   "source": [
    "**Let's play a little.**\n",
    "\n",
    "Pay attention to zoom and fps args of play function. Control: A, D, space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "WOIL47azsoUB"
   },
   "outputs": [],
   "source": [
    "# # Does not work in Colab.\n",
    "# Even on a local laptop breaks matplotlib rendering. So it's recommended to restart the notebook after playing.\n",
    "# # Use the Escape button to continue.\n",
    "\n",
    "# from gymnasium.utils.play import play\n",
    "\n",
    "# play(env=gym.make(ENV_NAME, render_mode=\"rgb_array\"), zoom=4, fps=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rhxy0nSyIZzv"
   },
   "source": [
    "## Wrapping the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "qrz_rpk_IZzv"
   },
   "outputs": [],
   "source": [
    "def make_basic_env():\n",
    "    return gym.make(ENV_NAME, render_mode=\"rgb_array\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5DPrxQuXsoUB"
   },
   "source": [
    "### Processing game image\n",
    "\n",
    "Let's check the shape and the dtype of the observation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "nfmbkV3FIZzv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((210, 160, 3), dtype('uint8'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = make_basic_env()\n",
    "obs, *_ = env.reset()\n",
    "obs.shape, obs.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vBihnYCuIZzv"
   },
   "source": [
    "Raw Atari images are large, 210x160x3 by default. However, we don't need that level of detail in order to learn from them.\n",
    "\n",
    "We can thus save a lot of time by preprocessing game image, including\n",
    "* Resizing to a smaller shape, 64x64 (or 84 x 84, which is used in literature)\n",
    "* Converting to grayscale\n",
    "* Cropping irrelevant image parts (top, bottom and edges) \\[we won't do this\\]\n",
    "\n",
    "The images are of the uint8 dtype.  \n",
    "uint8 stands for the 8-bit unsigned integer type.  \n",
    "We are going to store 10^5 or 10^6 observations in memory (RAM), so let's pay attention to preserving the 8-bit type after our transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "BYUjEIFsIZzv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84, 84) uint8\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def apply_gray_scale_wrap(env):\n",
    "    # With the argument values chosen as below, the gym.wrappers.AtariPreprocessing wrapper\n",
    "    # only converts images to grayscale and downsamples them the screen_size\n",
    "    env = gym.wrappers.AtariPreprocessing(\n",
    "        env,\n",
    "        noop_max=0,  # the default value 30 can be harmful with FireResetEnv and frame_skip=5\n",
    "        frame_skip=1,  # frame_skip has already been set to 5 inside the env\n",
    "        terminal_on_life_loss=False,  # we do this explicitly in the FireResetEnv wrapper\n",
    "        screen_size=84  # please use 84 (which is the standard value) or 64 (which will save some computations and memory)\n",
    "    )\n",
    "    return env\n",
    "\n",
    "\n",
    "env = make_basic_env()\n",
    "env = apply_gray_scale_wrap(env)\n",
    "\n",
    "obs, *_ = env.reset()\n",
    "\n",
    "assert obs.dtype == np.dtype('uint8'), obs_dtype\n",
    "\n",
    "print(obs.shape, obs.dtype)\n",
    "plt.imshow(obs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dSsVJAFYIZzv"
   },
   "source": [
    "### Atari specific wrappers\n",
    "\n",
    "We try to make our lives a little easier with the following wrappers:\n",
    "1. EpisodicLifeEnv it makes the signal that dropping a ball is not good more explicit\n",
    "2. Using FireResetEnv: with it the agent doesn't have to perform a special action to fire the ball in the beginning of a life"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil  # type: ignore\n",
    "\n",
    "\n",
    "def is_enough_ram(min_available_gb=0.1):\n",
    "    mem = psutil.virtual_memory()\n",
    "    return mem.available >= min_available_gb * (1024**3)\n",
    "\n",
    "\n",
    "def linear_decay(\n",
    "    init_val: float, final_val: float, cur_step: int, total_steps: int\n",
    ") -> float:\n",
    "    if cur_step >= total_steps:\n",
    "        return final_val\n",
    "    return (init_val * (total_steps - cur_step) + final_val * cur_step) / total_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymnasium import Wrapper\n",
    "\n",
    "\n",
    "class FireResetEnv(Wrapper):\n",
    "    def __init__(self, env):\n",
    "        \"\"\"Take action on reset for environments that are fixed until firing.\"\"\"\n",
    "        super().__init__(env)\n",
    "        assert env.unwrapped.get_action_meanings()[1] == \"FIRE\"\n",
    "        assert len(env.unwrapped.get_action_meanings()) >= 3\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        self.env.reset(**kwargs)\n",
    "        obs, _, terminated, truncated, _ = self.env.step(1)\n",
    "        if terminated or truncated:\n",
    "            self.env.reset(**kwargs)\n",
    "        obs, _, terminated, truncated, _ = self.env.step(2)\n",
    "        if terminated or truncated:\n",
    "            self.env.reset(**kwargs)\n",
    "        return obs, {}\n",
    "\n",
    "\n",
    "class EpisodicLifeEnv(Wrapper):\n",
    "    def __init__(self, env):\n",
    "        \"\"\"Make end-of-life == end-of-episode, but only reset on true game over.\n",
    "        Done by DeepMind for the DQN and co. since it helps value estimation.\n",
    "        \"\"\"\n",
    "        super().__init__(env)\n",
    "        self.lives = 0\n",
    "        self.was_real_done = True\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, reward, terminated, truncated, info = self.env.step(action)\n",
    "        self.was_real_done = terminated or truncated\n",
    "        # check current lives, make loss of life terminal,\n",
    "        # then update lives to handle bonus lives\n",
    "        lives = self.env.unwrapped.ale.lives()\n",
    "        if lives < self.lives and lives > 0:\n",
    "            # for Qbert sometimes we stay in lives == 0 condition for a few frames\n",
    "            # so it's important to keep lives > 0, so that we only reset once\n",
    "            # the environment advertises done.\n",
    "            terminated = True\n",
    "        self.lives = lives\n",
    "        return obs, reward, terminated, truncated, info\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        \"\"\"Reset only when lives are exhausted.\n",
    "        This way all states are still reachable even though lives are episodic,\n",
    "        and the learner need not know about any of this behind-the-scenes.\n",
    "        \"\"\"\n",
    "        if self.was_real_done:\n",
    "            obs, info = self.env.reset(**kwargs)\n",
    "        else:\n",
    "            # no-op step to advance from terminal/lost life state\n",
    "            obs, _, terminated, truncated, info = self.env.step(0)\n",
    "\n",
    "            # The no-op step can lead to a game over, so we need to check it again\n",
    "            # to see if we should reset the environment and avoid the\n",
    "            # monitor.py `RuntimeError: Tried to step environment that needs reset`\n",
    "            if terminated or truncated:\n",
    "                obs, info = self.env.reset(**kwargs)\n",
    "        self.lives = self.env.unwrapped.ale.lives()\n",
    "        return obs, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "zR0TqL5YIZzv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84, 84) uint8\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def apply_atary_specific_wrap(env):\n",
    "    env = EpisodicLifeEnv(env)\n",
    "    env = FireResetEnv(env)\n",
    "    return env\n",
    "\n",
    "env = make_basic_env()\n",
    "env = apply_gray_scale_wrap(env)\n",
    "env = apply_atary_specific_wrap(env)\n",
    "\n",
    "obs, *_ = env.reset()\n",
    "\n",
    "print(obs.shape, obs.dtype)\n",
    "plt.imshow(obs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X3f6Itm9IZzv"
   },
   "source": [
    "### FrameStack\n",
    "To make the game playable from a single observation (note the direction of the ball), we stack 4 consecutive frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "acE2hK9WIZzv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (4, 84, 84), dtype: uint8, Python object type: <class 'gymnasium.wrappers.frame_stack.LazyFrames'>\n",
      "\n",
      "Frames, left to right: from older to more recent. The ball is dropping.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N_FRAMES_STACKED = 4\n",
    "\n",
    "def make_final_env(apply_frame_stack=True):\n",
    "    \"\"\"\n",
    "    Builds the environment with all the wrappers applied.\n",
    "    The environment is meant be used directly as an RL algorithm input.\n",
    "\n",
    "    apply_frame_stack=False can be useful for vecotrized environments, \n",
    "    which are not required for this assignment.\n",
    "    \"\"\"\n",
    "    env = make_basic_env()\n",
    "    env = apply_gray_scale_wrap(env)\n",
    "    env = apply_atary_specific_wrap(env)\n",
    "    if apply_frame_stack:\n",
    "        env = gym.wrappers.FrameStack(env, 4)\n",
    "    return env\n",
    "\n",
    "\n",
    "env = make_final_env()\n",
    "\n",
    "obs, *_ = env.reset()\n",
    "print(f\"Shape: {obs.shape}, dtype: {obs.dtype}, Python object type: {type(obs)}\")\n",
    "for _ in range(N_FRAMES_STACKED - 1):\n",
    "    obs, *_ = env.step(env.action_space.sample())\n",
    "print()\n",
    "\n",
    "\n",
    "print(\"Frames, left to right: from older to more recent. The ball is dropping.\")\n",
    "_, axes = plt.subplots(figsize=(len(obs) * 3, 4), ncols=len(obs))\n",
    "for ax, frame in zip(axes, obs):\n",
    "    ax.imshow(frame)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "96N7Fo1LIZzw"
   },
   "source": [
    "**That is the final version of the environment we are going to do RL on.**\n",
    "\n",
    "**Let's discuss the representation of an obsevation.**\\\n",
    "An observation is a 4-frame-stack of grayscale images with reduced resolution.\\\n",
    "Memory (RAM) is a high-demand resource in this task. That's why:\n",
    "1. We use the uint8 dtype instead of float32 the neural network will operate on\n",
    "2. We don't represent them as numpy.ndarrays. **LazyFrames** are used by gym.wrappers.FrameStack instead. 2 consecutive observations share 3 of 4 frames. LazyFrames make use of this fact to save memory.\n",
    "When we feed the observations to neural networks, we should remember to scale them to the \\[-1, 1\\] range. We'll implement scaling as the first layer of a neural network, but that'll be later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8TAtOwpZIZzw"
   },
   "source": [
    "**The ball is dropping, but its hard to notice. Let's define a function to render more human-readable images:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "bIcMoltjIZzw"
   },
   "outputs": [],
   "source": [
    "# def merge_frame_stack_to_plot(frame_stack_obs: np.ndarray | gym.wrappers.frame_stack.LazyFrames):\n",
    "#     \"\"\"\n",
    "#     A helper function to plot a frame stack as a single human-interpretable image.\n",
    "\n",
    "#     Brighter pixels are more recent, pale pixels are older.\n",
    "#     Motions goes from pale to bright.\n",
    "\n",
    "#     Note! This function is designed for human vision convenience and it is NOT supposed to be used as part of\n",
    "#     data preprocessing for the Reinforcement Learning agent.\n",
    "#     \"\"\"\n",
    "#     weights = np.ones(frame_stack_obs.shape[0], dtype=float)\n",
    "#     weights[-1] += weights.sum()\n",
    "#     weights /= weights.sum()\n",
    "#     result = (weights[:, None, None] * frame_stack_obs).sum(0)\n",
    "#     return result\n",
    "\n",
    "\n",
    "# obs_joint = merge_frame_stack_to_plot(obs)\n",
    "# plt.imshow(obs_joint)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nRK1ngI1IZzw"
   },
   "source": [
    "Hope that's better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ciZqI4ZTIZzw"
   },
   "outputs": [],
   "source": [
    "N_ACTIONS = env.action_space.n\n",
    "STATE_SHAPE = env.observation_space.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4iJM3IAwsoUB"
   },
   "source": [
    "**Let's see if the game is still playable after applying the wrappers.**\n",
    "At playing the EpisodicLifeEnv wrapper seems not to work but actually it does (because after when life finishes a new ball is dropped automatically - it means that FireResetEnv wrapper understands that a new episode began).\n",
    "\n",
    "**Not supported for now.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jhiOKsQvsoUC"
   },
   "source": [
    "## DQN as it is (10 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aspwJFiGsoUC"
   },
   "source": [
    "### Building a network\n",
    "\n",
    "We now need to build a neural network that can map images to state q-values. This network will be called on every agent's step so it better not be resnet-152 unless you have an array of GPUs. Instead, you can use strided convolutions with a small number of features to save time and memory.\n",
    "\n",
    "You can build any architecture you want, but you can find a couple of examples on diagrams below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YbZIucfksoUC"
   },
   "source": [
    "**Dueling network:**\\\n",
    "Paper: https://arxiv.org/pdf/1511.06581.pdf\n",
    "$$Q_{\\theta}(s, a) = V_{\\eta}(f_{\\xi}(s)) + A_{\\psi}(f_{\\xi}(s), a) - \\frac{\\sum_{a'}A_{\\psi}(f_{\\xi}(s), a')}{N_{actions}},$$\n",
    "where $\\xi$, $\\eta$, and $\\psi$ are, respectively, the parameters of the\n",
    "shared encoder $f_ξ$ , of the value stream $V_\\eta$ , and of the advantage stream $A_\\psi$; and $\\theta = \\{\\xi, \\eta, \\psi\\}$ is their concatenation.\n",
    "\n",
    "This is what it looks like:\n",
    "\n",
    "Simple, expects height=width=64\n",
    "\n",
    "<img src=\"https://github.com/yandexdataschool/Practical_RL/blob/master/week04_approx_rl/img/dueling_basic.png?raw=1\" alt=\"dueling_basic\" width=\"500\"/>\n",
    "\n",
    "Nature DQN ([2]), expects height=width=84\n",
    "\n",
    "<img src=\"https://github.com/yandexdataschool/Practical_RL/blob/master/week04_approx_rl/img/dueling_nature.png?raw=1\" alt=\"dueling_nature\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "SPPmY6wIsoUC"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/george/envs/rlearn/lib/python3.10/site-packages/torch/cuda/__init__.py:82: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3aaalYOOIZz0"
   },
   "source": [
    "These constants will be useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "_1FVWFvIIZz0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_ACTIONS, N_FRAMES_STACKED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "_5xsfS8GIZz0"
   },
   "outputs": [],
   "source": [
    "class ConvBackbone(nn.Sequential):\n",
    "    \"\"\"\n",
    "    The convolutional part of a DQN model.\n",
    "    Please, don't think about input scaling here: it will be implemented below.\n",
    "    \"\"\"\n",
    "    def __init__(self, c_in: int = N_FRAMES_STACKED) -> None:\n",
    "        super().__init__(\n",
    "            nn.Conv2d(in_channels=c_in,\n",
    "                      out_channels=32,\n",
    "                      kernel_size=8,\n",
    "                      stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32,\n",
    "                      out_channels=64,\n",
    "                      kernel_size=4,\n",
    "                      stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64,\n",
    "                      out_channels=64,\n",
    "                      kernel_size=3,\n",
    "                      stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "class DuelingDqnHead(nn.Module):\n",
    "    \"\"\"\n",
    "    Implenets the Dueling DQN logic.\n",
    "    Please, don't think about gradient scaling here (if you know what it is about): it will be implemented below.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_actions, inp_size=64 * 7 * 7, hidden_size=512) -> None:\n",
    "        super().__init__()\n",
    "        self.adv_stream = nn.Sequential(\n",
    "            nn.Linear(in_features=inp_size,\n",
    "                      out_features=hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_size,\n",
    "                      out_features=n_actions)\n",
    "        )\n",
    "\n",
    "        self.value_stream = nn.Sequential(\n",
    "            nn.Linear(in_features=inp_size,\n",
    "                      out_features=hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_size,\n",
    "                      out_features=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        assert x.ndim == 2, x.shape  # (batch_size, n_features)\n",
    "        # your code\n",
    "        # When calculating the mean advantage, please, remember, x is a batched input!\n",
    "        x_adv = self.adv_stream(x)\n",
    "        x_adv = x_adv - torch.mean(x_adv, 1, True)\n",
    "        x_value = self.value_stream(x)\n",
    "        return x_adv + x_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fr7IRpP_IZz1"
   },
   "source": [
    "Let's make a simple test for the network architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "qa2vLVAwIZz1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed!\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def test_network_part_shapes(backbone, head):\n",
    "    batch_size = 3\n",
    "    env = make_final_env()\n",
    "    s, _ = env.reset()\n",
    "    inp = torch.rand(batch_size, *s.shape)\n",
    "\n",
    "    features = backbone(inp)\n",
    "    qvalues = head(features)\n",
    "\n",
    "    assert features.ndim == 2, features.shape\n",
    "    assert features.shape[0] == batch_size, features.shape\n",
    "\n",
    "    assert qvalues.ndim == 2, qvalues.shape\n",
    "    assert qvalues.shape[0] == batch_size, qvalues.shape\n",
    "    assert qvalues.shape[1] == N_ACTIONS, qvalues.shape\n",
    "\n",
    "    print(\"Test passed!\")\n",
    "\n",
    "test_network_part_shapes(\n",
    "    backbone=ConvBackbone(N_FRAMES_STACKED),\n",
    "    head=DuelingDqnHead(N_ACTIONS),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0VW8Xtc0IZz1"
   },
   "source": [
    "**Now let's build a full model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Q_R_qaeIIZz1"
   },
   "outputs": [],
   "source": [
    "MAX_UINT_8 = 2 ** 8 - 1\n",
    "\n",
    "\n",
    "class InputScaler(nn.Module):\n",
    "    def __init__(self, mult=1 / MAX_UINT_8):\n",
    "        super().__init__()\n",
    "        self.mult = mult\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return x * self.mult\n",
    "\n",
    "\n",
    "class GradScalerFunctional(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    A torch.autograd.Function works as Identity on forward pass\n",
    "    and scales the gradient by scale_factor on backward pass.\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, scale_factor):\n",
    "        ctx.scale_factor = scale_factor\n",
    "        return input\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        scale_factor = ctx.scale_factor\n",
    "        grad_input = grad_output * scale_factor\n",
    "        return grad_input, None\n",
    "\n",
    "\n",
    "class GradScaler(nn.Module):\n",
    "    \"\"\"\n",
    "    An nn.Module incapsulating GradScalerFunctional\n",
    "    \"\"\"\n",
    "    def __init__(self, scale_factor: float):\n",
    "        super().__init__()\n",
    "        self.scale_factor = scale_factor\n",
    "\n",
    "    def forward(self, x):\n",
    "        return GradScalerFunctional.apply(x, self.scale_factor)\n",
    "\n",
    "\n",
    "class DQNetworkDueling(nn.Sequential):\n",
    "    def __init__(self, c_in: int, n_actions: int) -> None:\n",
    "        input_scaler = InputScaler()  # the inputs come from the uint8 range\n",
    "        backbone = ConvBackbone(c_in=c_in)  # your code\n",
    "        grad_scaler = GradScaler(1 / 2**0.5)  # Dueling DQN suggests do scale the gradient by 1 / sqrt(2)\n",
    "        head = DuelingDqnHead(n_actions=n_actions)\n",
    "        super().__init__(input_scaler, backbone, grad_scaler, head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "G40CuKJRIZz1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed!\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def test_network_shapes(model):\n",
    "    batch_size = 3\n",
    "    env = make_final_env()\n",
    "    s, _ = env.reset()\n",
    "    inp = torch.rand(batch_size, *s.shape)\n",
    "\n",
    "    qvalues = model(inp)\n",
    "\n",
    "    assert qvalues.ndim == 2, qvalues.shape\n",
    "    assert qvalues.shape[0] == batch_size, qvalues.shape\n",
    "    assert qvalues.shape[1] == N_ACTIONS, qvalues.shape\n",
    "\n",
    "    print(\"Test passed!\")\n",
    "\n",
    "test_network_shapes(model=DQNetworkDueling(N_FRAMES_STACKED, N_ACTIONS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UqK9X6vsIZz1"
   },
   "source": [
    "**Now let's wrap our model into an Agent class.**  \n",
    "It will implement epsilon-greedy policy on numpy ndarrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "nmfaSzm2IZz1"
   },
   "outputs": [],
   "source": [
    "class DQNAgent(nn.Module):\n",
    "    \"\"\"\n",
    "    Epsilon-greedy policy with a torch.nn.Module Q-value estimator.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, q_network: nn.Module, epsilon=1) -> None:\n",
    "        super().__init__()\n",
    "        self.epsilon = epsilon\n",
    "        self.q_network = q_network\n",
    "\n",
    "    def forward(self, state_t):\n",
    "        \"\"\"\n",
    "        takes agent's observation (tensor), returns qvalues (tensor)\n",
    "        :param state_t: a batch of 4-frame buffers, shape = [batch_size, 4, h, w]\n",
    "        \"\"\"\n",
    "        # Use your network to compute qvalues for given state\n",
    "        qvalues =  self.q_network(state_t)\n",
    "        return qvalues\n",
    "\n",
    "    @torch.no_grad()  # we don't need autograd here, so let's save the computations\n",
    "    def get_qvalues(self, states: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        like forward, but works on numpy arrays, not tensors\n",
    "        \"\"\"\n",
    "        model_device = next(self.parameters()).device\n",
    "        states_pt = torch.tensor(\n",
    "            np.array(states), device=model_device, dtype=torch.float32\n",
    "        )\n",
    "        # Use your network to compute qvalues for given state\n",
    "        qvalues_pt = self.q_network(states_pt)\n",
    "        qvalues = qvalues_pt.data.cpu().numpy()\n",
    "        return qvalues\n",
    "\n",
    "    def sample_actions_by_qvalues(self, qvalues: np.ndarray, greedy: bool = False) -> np.ndarray:\n",
    "        \"\"\"pick actions given qvalues. Uses epsilon-greedy exploration strategy.\"\"\"\n",
    "        batch_size, n_actions = qvalues.shape\n",
    "        if greedy:\n",
    "            greedy_actions = qvalues.argmax(axis=-1)\n",
    "            return greedy_actions\n",
    "\n",
    "        random_actions = np.random.randint(0, n_actions, size=batch_size)\n",
    "        should_explore = np.random.binomial(1, self.epsilon, size=batch_size)\n",
    "        epsilon_greedy_actions = np.where(\n",
    "            should_explore, random_actions, qvalues.argmax(axis=-1)\n",
    "        )\n",
    "        return epsilon_greedy_actions\n",
    "\n",
    "    def sample_actions(self, states: np.ndarray, greedy: bool = False) -> np.ndarray:\n",
    "        qvalues = self.get_qvalues(states)\n",
    "        actions = self.sample_actions_by_qvalues(qvalues, greedy=greedy)\n",
    "        return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "rn83ZFhRIZz2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed!\n"
     ]
    }
   ],
   "source": [
    "test_network_shapes(\n",
    "    model=DQNAgent(DQNetworkDueling(N_FRAMES_STACKED, N_ACTIONS))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "BUFMLKX1soUC"
   },
   "outputs": [],
   "source": [
    "agent = DQNAgent(\n",
    "    DQNetworkDueling(N_FRAMES_STACKED, N_ACTIONS),\n",
    "    epsilon=0.5\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XbsIT2EdsoUC"
   },
   "source": [
    "Now let's try out our agent to see if it raises any errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "pZR3qE2esoUC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n",
      "1.4\n"
     ]
    }
   ],
   "source": [
    "def evaluate(env, agent, n_games=1, greedy=False, t_max=10000, seed=None):\n",
    "    \"\"\" Plays n_games full games. If greedy, picks actions as argmax(qvalues). Returns mean reward. \"\"\"\n",
    "    rewards = []\n",
    "    for _ in range(n_games):\n",
    "        s, _ = env.reset(seed=seed)\n",
    "        reward = 0\n",
    "        for _ in range(t_max):\n",
    "            action = agent.sample_actions(np.array(s)[None], greedy=greedy)[0]\n",
    "            s, r, terminated, truncated, _ = env.step(action)\n",
    "            reward += r\n",
    "            if terminated or truncated:\n",
    "                break\n",
    "\n",
    "        rewards.append(reward)\n",
    "    return np.mean(rewards)\n",
    "\n",
    "print(evaluate(env, agent, n_games=50, greedy=False))\n",
    "print(evaluate(env, agent, n_games=50, greedy=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2BiRixA-soUC"
   },
   "source": [
    "### Experience replay\n",
    "For this assignment, we provide you with experience replay buffer.\n",
    "\n",
    "<img src=\"https://github.com/yandexdataschool/Practical_RL/blob/master/week04_approx_rl/img/exp_replay.png?raw=1\" alt=\"exp_replay\" width=\"500\"/>\n",
    "<!-- ![img](https://github.com/yandexdataschool/Practical_RL/raw/master/yet_another_week/_resource/exp_replay.png) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jTBZo5BVsoUC"
   },
   "source": [
    "#### The interface is fairly simple:\n",
    "* `exp_replay.add(obs, act, rw, next_obs, done)` - saves (s,a,r,s',done) tuple into the buffer\n",
    "* `exp_replay.sample(batch_size)` - returns observations, actions, rewards, next_observations and is_done for `batch_size` random samples.\n",
    "* `len(exp_replay)` - returns number of elements stored in replay buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "class ReplayBuffer(object):\n",
    "    def __init__(self, size):\n",
    "        \"\"\"Create Replay buffer.\n",
    "        Parameters\n",
    "        ----------\n",
    "        size: int\n",
    "            Max number of transitions to store in the buffer. When the buffer\n",
    "            overflows the old memories are dropped.\n",
    "        \"\"\"\n",
    "        self._storage = []\n",
    "        self._maxsize = size\n",
    "        self._next_idx = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._storage)\n",
    "\n",
    "    def add(self, obs_t, action, reward, obs_tp1, done):\n",
    "        data = (obs_t, action, reward, obs_tp1, done)\n",
    "\n",
    "        if self._next_idx >= len(self._storage):\n",
    "            self._storage.append(data)\n",
    "        else:\n",
    "            self._storage[self._next_idx] = data\n",
    "        self._next_idx = (self._next_idx + 1) % self._maxsize\n",
    "\n",
    "    def _encode_sample(self, idxes):\n",
    "        obses_t, actions, rewards, obses_tp1, dones = [], [], [], [], []\n",
    "        for i in idxes:\n",
    "            data = self._storage[i]\n",
    "            obs_t, action, reward, obs_tp1, done = data\n",
    "            obses_t.append(np.array(obs_t, copy=False))\n",
    "            actions.append(np.array(action, copy=False))\n",
    "            rewards.append(reward)\n",
    "            obses_tp1.append(np.array(obs_tp1, copy=False))\n",
    "            dones.append(done)\n",
    "        return (\n",
    "            np.array(obses_t),\n",
    "            np.array(actions),\n",
    "            np.array(rewards),\n",
    "            np.array(obses_tp1),\n",
    "            np.array(dones),\n",
    "        )\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        \"\"\"Sample a batch of experiences.\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch_size: int\n",
    "            How many transitions to sample.\n",
    "        Returns\n",
    "        -------\n",
    "        obs_batch: np.array\n",
    "            batch of observations\n",
    "        act_batch: np.array\n",
    "            batch of actions executed given obs_batch\n",
    "        rew_batch: np.array\n",
    "            rewards received as results of executing act_batch\n",
    "        next_obs_batch: np.array\n",
    "            next set of observations seen after executing act_batch\n",
    "        done_mask: np.array\n",
    "            done_mask[i] = 1 if executing act_batch[i] resulted in\n",
    "            the end of an episode and 0 otherwise.\n",
    "        \"\"\"\n",
    "        idxes = [random.randint(0, len(self._storage) - 1) for _ in range(batch_size)]\n",
    "        return self._encode_sample(idxes)\n",
    "\n",
    "\n",
    "class LazyFramesVectorReplayBuffer(ReplayBuffer):\n",
    "    \"\"\"\n",
    "    ReplayBuffer for vectorized environments, which are wrapped into FrameBuffers.\n",
    "\n",
    "    If an environment is first wrapped into a FrameBuffer and then vectorized,\n",
    "    then the resulting VecEnv will not use LazyFrames, but it will directly\n",
    "    use np.ndarrays, thus greatly increasing RAM consumption by the buffer.\n",
    "\n",
    "    Instead, we first vectorize an environment and only then wrap in into FrameBuffers.\n",
    "    It's not as convenient, but it keeps the advantage in memory from LazyFrames.\n",
    "\n",
    "    So,\n",
    "    observations and next_obervations are stored as LazyFrames\n",
    "    of shape (n_frames, n_envs, ...)\n",
    "    actions, rewards and dones are stored as np.ndarrays of shape (n_envs,).\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # (n_frames, n_envs, *)\n",
    "\n",
    "    def _encode_sample(self, idxes):\n",
    "        \"\"\"\n",
    "        For each index in idxes samples a (s, a, r, s', done) transition\n",
    "        from a randomly chosen environment of the corresponding VecEnv.\n",
    "        \"\"\"\n",
    "        obses_t, actions, rewards, obses_tp1, dones = [], [], [], [], []\n",
    "        for i in idxes:\n",
    "            data = self._storage[i]\n",
    "            obs_t, action, reward, obs_tp1, done = data\n",
    "            n_envs = action.shape[0]\n",
    "            env_idx_chosen_for_sample = random.randint(0, n_envs - 1)\n",
    "            obses_t.append(\n",
    "                np.array(obs_t, copy=False)[:, env_idx_chosen_for_sample],\n",
    "            )\n",
    "            actions.append(np.array(action, copy=False)[env_idx_chosen_for_sample])\n",
    "            rewards.append(reward[env_idx_chosen_for_sample])\n",
    "            obses_tp1.append(\n",
    "                np.array(obs_tp1, copy=False)[:, env_idx_chosen_for_sample],\n",
    "            )\n",
    "            dones.append(done[env_idx_chosen_for_sample])\n",
    "        return (\n",
    "            np.array(obses_t),\n",
    "            np.array(actions),\n",
    "            np.array(rewards),\n",
    "            np.array(obses_tp1),\n",
    "            np.array(dones),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Ydi0KK9LsoUC"
   },
   "outputs": [],
   "source": [
    "\n",
    "exp_replay = ReplayBuffer(10)\n",
    "\n",
    "for _ in range(30):\n",
    "    exp_replay.add(env.reset()[0], env.action_space.sample(), 1.0, env.reset()[0], done=False)\n",
    "\n",
    "obs_batch, act_batch, reward_batch, next_obs_batch, is_done_batch = exp_replay.sample(5)\n",
    "\n",
    "assert len(exp_replay) == 10, \"experience replay size should be 10 because that's what maximum capacity is\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I08i8oO1IZz2"
   },
   "source": [
    "**The `play_and_record` function, defined below is the main way the agent will interact with the environment during training.**\n",
    "\n",
    "Previously we used to train RL algorithms on entire episodes.  \n",
    "\n",
    "This time we keep the environment constantly running and will be getting small portions of interactions with it.\n",
    "\n",
    "The agent takes several actions (4 actions in [2] and [3]), the corresponding (s, a, r, s', terminated) tuples are put into the replay buffer.  \n",
    "Whenever an episode finishes (i.e. `truncated or terminated`), the environment is reset and the procedure continues as usually.  \n",
    "\n",
    "To make the first step in a constantly running environment, the agent needs to know the state of the environment. This is the meaning of the `initial_state` argument of the function.\n",
    "\n",
    "It's worth noting, the agent does not train on the fresh tuples immediately. The agent trains on samples which are sampled from the buffer.\n",
    "\n",
    "**Implementation note:**\n",
    "We define an `ActionSampler` protocol. The goal of it is to let the function `play_and_record` accept not only `DQNAgent` class instances, but any object that can sample actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "cEXv69KWsoUC"
   },
   "outputs": [],
   "source": [
    "from typing import Protocol\n",
    "\n",
    "\n",
    "class ActionSampler(Protocol):\n",
    "    \"\"\"\n",
    "    A protocol which defines an Callable which samples actions from states\n",
    "    \"\"\"\n",
    "    def __call__(self, state: gym.wrappers.frame_stack.LazyFrames) -> int: ...\n",
    "\n",
    "\n",
    "class RandomActionSampler:\n",
    "    \"\"\"\n",
    "    We will need this guy to fill the buffer with initial 50-200K observations from a random policy.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, action_space) -> None:\n",
    "        self.action_space = action_space\n",
    "\n",
    "    def __call__(self, state: gym.wrappers.frame_stack.LazyFrames) -> int:\n",
    "        action = self.action_space.sample()\n",
    "        return action\n",
    "\n",
    "\n",
    "class DqnActionSampler:\n",
    "    \"\"\"\n",
    "    DQNAgent works on batched np.ndarray inputs.\n",
    "    This class uses a DQNAgent to sample actions from single LazyFrames observations.\n",
    "\n",
    "    This will be an epsilon-greedy sampler.\n",
    "    A greedy sampler can be defined as well, but we won't need it.\n",
    "    \"\"\"\n",
    "    def __init__(self, agent: DQNAgent):\n",
    "        self.agent = agent\n",
    "\n",
    "    def __call__(self, state: gym.wrappers.frame_stack.LazyFrames) -> int:\n",
    "        state_batched = np.array(state)[None]\n",
    "        action_batched = self.agent.sample_actions(state_batched)\n",
    "        action = action_batched.item()\n",
    "        return action\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def play_and_record(initial_state: gym.wrappers.frame_stack.LazyFrames, action_sampler: ActionSampler, env, exp_replay, n_steps=1):\n",
    "    \"\"\"\n",
    "    Play the game for exactly n_steps, record every (s,a,r,s', done) to replay buffer.\n",
    "    Whenever game ends due to termination or truncation, add record with done=terminated and reset the game.\n",
    "    It is guaranteed that env has terminated=False when passed to this function.\n",
    "\n",
    "    PLEASE DO NOT RESET ENV UNLESS IT IS \"DONE\"\n",
    "\n",
    "    :returns: return sum of rewards over time and the state in which the env stays\n",
    "    \"\"\"\n",
    "    s = initial_state\n",
    "    sum_rewards = 0\n",
    "\n",
    "    # Play the game for n_steps as per instructions above\n",
    "    for _ in range(n_steps):\n",
    "        action = action_sampler(s)\n",
    "        s_new, r, terminated, truncated, _ = env.step(action)\n",
    "        sum_rewards += r\n",
    "\n",
    "        if terminated or truncated:\n",
    "            exp_replay.add(s, action, r, s_new, done=terminated)\n",
    "            env.reset()\n",
    "        else:\n",
    "            exp_replay.add(s, action, r, s_new, done=False)\n",
    "\n",
    "        s = s_new\n",
    "\n",
    "    return sum_rewards, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "oKncMrXzIZz3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random:\n",
      "Well done!\n",
      "DQN:\n",
      "Well done!\n"
     ]
    }
   ],
   "source": [
    "def test_play_and_record(action_sampler):\n",
    "    exp_replay = ReplayBuffer(10_000)\n",
    "\n",
    "    state, _ = env.reset()\n",
    "\n",
    "    # action_sampler = RandomActionSampler(env.action_space)\n",
    "    # action_sampler = DqnActionSampler(agent)\n",
    "    play_and_record(state, action_sampler, env, exp_replay, n_steps=1000);\n",
    "\n",
    "    # if you're using your own experience replay buffer, some of those tests may need correction.\n",
    "    # just make sure you know what your code does\n",
    "    assert len(exp_replay) == 1000, \\\n",
    "        \"play_and_record should have added exactly 1000 steps, \" \\\n",
    "        \"but instead added %i\" % len(exp_replay)\n",
    "    is_dones = list(zip(*exp_replay._storage))[-1]\n",
    "\n",
    "    assert 0 < np.mean(is_dones) < 0.1, \\\n",
    "        \"Please make sure you restart the game whenever it is 'done' and \" \\\n",
    "        \"record the is_done correctly into the buffer. Got %f is_done rate over \" \\\n",
    "        \"%i steps. [If you think it's your tough luck, just re-run the test]\" % (\n",
    "            np.mean(is_dones), len(exp_replay))\n",
    "\n",
    "    for _ in range(100):\n",
    "        obs_batch, act_batch, reward_batch, next_obs_batch, is_done_batch = exp_replay.sample(10)\n",
    "        assert obs_batch.shape == next_obs_batch.shape == (10,) + STATE_SHAPE\n",
    "        assert act_batch.shape == (10,), \\\n",
    "            \"actions batch should have shape (10,) but is instead %s\" % str(act_batch.shape)\n",
    "        assert reward_batch.shape == (10,), \\\n",
    "            \"rewards batch should have shape (10,) but is instead %s\" % str(reward_batch.shape)\n",
    "        assert is_done_batch.shape == (10,), \\\n",
    "            \"is_done batch should have shape (10,) but is instead %s\" % str(is_done_batch.shape)\n",
    "        assert [int(i) in (0, 1) for i in is_dones], \\\n",
    "            \"is_done should be strictly True or False\"\n",
    "        assert [0 <= a < N_ACTIONS for a in act_batch], \"actions should be within [0, n_actions)\"\n",
    "\n",
    "    print(\"Well done!\")\n",
    "\n",
    "\n",
    "env = make_final_env()\n",
    "\n",
    "agent = DQNAgent(\n",
    "    DQNetworkDueling(N_FRAMES_STACKED, N_ACTIONS),\n",
    "    epsilon=0.5\n",
    ").to(device)\n",
    "\n",
    "print(\"Random:\")\n",
    "test_play_and_record(RandomActionSampler(env.action_space))\n",
    "print(\"DQN:\")\n",
    "test_play_and_record(DqnActionSampler(agent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y5zyryPOsoUF"
   },
   "source": [
    "### Target networks\n",
    "\n",
    "We also employ the so called \"target network\" - a copy of neural network weights to be used for reference Q-values:\n",
    "\n",
    "The network itself is an exact copy of agent network, but it's parameters are not trained. Instead, they are moved here from agent's actual network every so often.\n",
    "\n",
    "$$ Q_{reference}(s,a) = r + \\gamma \\cdot \\max _{a'} Q_{target}(s',a') $$\n",
    "\n",
    "![img](https://github.com/yandexdataschool/Practical_RL/raw/master/yet_another_week/_resource/target_net.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "wL1Ep-_yIZz3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_network = DQNetworkDueling(N_FRAMES_STACKED, N_ACTIONS).to(device)\n",
    "target_network.load_state_dict(agent.q_network.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2idY8QX0soUF"
   },
   "source": [
    "### Learning with... Q-learning\n",
    "Here we write a function similar to `agent.update` from tabular q-learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k46MPwwwsoUF"
   },
   "source": [
    "Compute Q-learning TD error:\n",
    "\n",
    "$$ L = { 1 \\over N} \\sum_i [ Q_{\\theta}(s,a) - Q_{reference}(s,a) ] ^2 $$\n",
    "\n",
    "With Q-reference defined as\n",
    "\n",
    "$$ Q_{reference}(s,a) = r(s,a) + \\gamma \\cdot max_{a'} Q_{target}(s', a') $$\n",
    "\n",
    "Where\n",
    "* $Q_{target}(s',a')$ denotes Q-value of next state and next action predicted by __target_network__\n",
    "* $s, a, r, s'$ are current state, action, reward and next state respectively\n",
    "* $\\gamma$ is a discount factor defined two cells above.\n",
    "\n",
    "\n",
    "__Note 1:__ there's an example input below. Feel free to experiment with it before you write the function.\n",
    "\n",
    "__Note 2:__ compute_td_loss is a major source of of bugs in this homework. We tried to cover it with tests, but if reward doesn't improve, it often helps to go through it line by line [with a rubber duck](https://rubberduckdebugging.com/).\n",
    "\n",
    "**Double DQN**\n",
    "\n",
    "$$ Q_{reference}(s,a) = r(s, a) + \\gamma \\cdot\n",
    "Q_{target}(s',argmax_{a'}Q_\\theta(s', a')) $$\n",
    "\n",
    "We will use Double DQN for training, but **we ask you to implement both** of the methods to experience the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "V02HcUYasoUG"
   },
   "outputs": [],
   "source": [
    "def compute_td_loss_on_tensors(\n",
    "    states: torch.Tensor,       # (batch_size, *state_shape)\n",
    "    actions: torch.Tensor,      # (batch_size,)\n",
    "    rewards: torch.Tensor,      # (batch_size,)\n",
    "    next_states: torch.Tensor,  # (batch_size, *state_shape)\n",
    "    is_done: torch.Tensor,      # (batch_size,), torch.bool\n",
    "    agent: nn.Module,\n",
    "    target_network: nn.Module,\n",
    "    gamma: float = 0.99,\n",
    "    check_shapes=False,\n",
    "):\n",
    "    predicted_qvalues = agent(states)  # shape: [batch_size, n_actions]\n",
    "    assert is_done.dtype is torch.bool\n",
    "\n",
    "    # compute q-values for all actions in next states\n",
    "    with torch.no_grad():\n",
    "        predicted_next_qvalues_target = target_network(next_states)  # shape: [batch_size, n_actions]\n",
    "\n",
    "    # select q-values for chosen actions\n",
    "    predicted_qvalues_for_actions = predicted_qvalues[\n",
    "        range(len(actions)), actions\n",
    "    ]  # shape: [batch_size]\n",
    "\n",
    "    # compute V*(next_states) using predicted next q-values\n",
    "    next_state_values =  torch.max(predicted_next_qvalues_target, 1)[0]\n",
    "\n",
    "    if check_shapes:\n",
    "        assert (\n",
    "            next_state_values.dim() == 1\n",
    "            and next_state_values.shape[0] == states.shape[0]\n",
    "        ), \"must predict one value per state\"\n",
    "        assert not next_state_values.requires_grad\n",
    "\n",
    "    # compute \"target q-values\" for loss - it's what's inside square parentheses in the above formula.\n",
    "    # at the last state use the simplified formula: Q(s,a) = r(s,a) since s' doesn't exist\n",
    "    # So we want to calculate Q_target_(s, a) - Q_reference(s, a)\n",
    "\n",
    "    #target_qvalues_for_actions = rewards + (gamma * next_state_values if not is_done else 0)\n",
    "    # We cannot use the line above because it does not work with boolean vectors\n",
    "    target_qvalues_for_actions = torch.where(is_done, rewards, rewards + (gamma * next_state_values))\n",
    "\n",
    "    # mean squared error loss to minimize\n",
    "    loss = torch.mean((predicted_qvalues_for_actions - target_qvalues_for_actions) ** 2)\n",
    "\n",
    "    if check_shapes:\n",
    "        assert (\n",
    "            predicted_next_qvalues_target.data.dim() == 2\n",
    "        ), \"make sure you predicted q-values for all actions in next state\"\n",
    "        assert (\n",
    "            next_state_values.data.dim() == 1\n",
    "        ), \"make sure you computed V(s') as maximum over just the actions axis and not all axes\"\n",
    "        assert (\n",
    "            target_qvalues_for_actions.data.dim() == 1\n",
    "        ), \"there's something wrong with target q-values, they must be a vector\"\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import Protocol\n",
    "\n",
    "\n",
    "class ComputeTdLossProtocol(Protocol):\n",
    "    \"\"\"\n",
    "    An Protocol which the compute_td_loss function should match.\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(\n",
    "        self,\n",
    "        states: torch.Tensor,\n",
    "        actions: torch.Tensor,\n",
    "        rewards: torch.Tensor,\n",
    "        next_states: torch.Tensor,\n",
    "        is_done: torch.Tensor,\n",
    "        agent: nn.Module,\n",
    "        target_network: nn.Module,\n",
    "        gamma: float,\n",
    "    ):\n",
    "        pass\n",
    "\n",
    "\n",
    "class MockAgent(nn.Module):\n",
    "    \"\"\"\n",
    "    An nn.Module, which outputs a value which does not depend on its input.\n",
    "    Designed to be used for testing the compute_td_loss function.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_q_values: torch.Tensor):\n",
    "        super().__init__()\n",
    "        assert output_q_values.dtype == torch.float, output_q_values.dtype\n",
    "        assert output_q_values.ndim == 2, output_q_values.shape\n",
    "        self.output_q_values = nn.Parameter(output_q_values)\n",
    "\n",
    "    def forward(self, state):\n",
    "        return torch.clone(self.output_q_values)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test_is_done_is_used(compute_td_loss: ComputeTdLossProtocol):\n",
    "    \"\"\"\n",
    "    Tries to catch the error when compute_td_loss ignores its is_done argument.\n",
    "    \"\"\"\n",
    "\n",
    "    states = torch.empty(1)\n",
    "    actions = torch.tensor([0])\n",
    "    rewards = torch.tensor([1], dtype=torch.float)\n",
    "    is_done_first = torch.tensor([True])\n",
    "    is_done_second = torch.tensor([False])\n",
    "    next_states = torch.empty(1)\n",
    "    gamma = 0.99\n",
    "\n",
    "    q_values_agent = torch.tensor([[1, 1, 1]], dtype=torch.float)\n",
    "    q_values_target_network = torch.tensor([[1, 1, 1]], dtype=torch.float)\n",
    "    agent = MockAgent(q_values_agent)\n",
    "    target_network = MockAgent(q_values_target_network)\n",
    "\n",
    "    loss_kwargs = dict(\n",
    "        states=states,\n",
    "        actions=actions,\n",
    "        rewards=rewards,\n",
    "        next_states=next_states,\n",
    "        agent=agent,\n",
    "        target_network=target_network,\n",
    "        gamma=gamma,\n",
    "    )\n",
    "\n",
    "    loss_first = compute_td_loss(is_done=is_done_first, **loss_kwargs).item()\n",
    "    loss_second = compute_td_loss(is_done=is_done_second, **loss_kwargs).item()\n",
    "\n",
    "    abs_diff = abs(loss_first - loss_second)\n",
    "    if abs_diff > 0.5:\n",
    "        msg = \"compute_td_loss returned close values for different is_done inputs\"\n",
    "\n",
    "    assert abs(loss_first - loss_second) > 0.5, msg\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test_compute_td_loss_vanilla(compute_td_loss: ComputeTdLossProtocol):\n",
    "    \"\"\"\n",
    "    Checks compute_td_loss on manually precomputed examples.\n",
    "    Note: this is a test for vanilla compute_td_loss\n",
    "    and it should NOT be used for double_dqn\n",
    "    \"\"\"\n",
    "\n",
    "    samples = [\n",
    "        {\n",
    "            \"q_agent\": [0, 1, 2],\n",
    "            \"action\": 1,\n",
    "            \"is_done\": False,\n",
    "            \"q_target\": [0, 1, 2],\n",
    "            \"gamma\": 0.5,\n",
    "            \"reward\": 5,\n",
    "            \"answer\": 25,\n",
    "        },\n",
    "        {\n",
    "            \"q_agent\": [0, 1, 2],\n",
    "            \"action\": 1,\n",
    "            \"is_done\": False,\n",
    "            \"q_target\": [2, 0, 1],\n",
    "            \"gamma\": 0.5,\n",
    "            \"reward\": 5,\n",
    "            \"answer\": 25,\n",
    "        },\n",
    "        {\n",
    "            \"q_agent\": [3, 1, 2],\n",
    "            \"action\": 1,\n",
    "            \"is_done\": True,\n",
    "            \"q_target\": [0, 1, 2],\n",
    "            \"gamma\": 0.5,\n",
    "            \"reward\": 5,\n",
    "            \"answer\": 16,\n",
    "        },\n",
    "        {\n",
    "            \"q_agent\": [0, 1, 2],\n",
    "            \"action\": 0,\n",
    "            \"is_done\": False,\n",
    "            \"q_target\": [0, 1, 2],\n",
    "            \"gamma\": 0.5,\n",
    "            \"reward\": 5,\n",
    "            \"answer\": 36,\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    for sample in samples:\n",
    "        agent = MockAgent(torch.tensor(sample[\"q_agent\"], dtype=torch.float)[None])\n",
    "        tn = MockAgent(torch.tensor(sample[\"q_target\"], dtype=torch.float)[None])\n",
    "        ans = compute_td_loss(\n",
    "            states=torch.empty(1),\n",
    "            actions=torch.tensor(sample[\"action\"])[None],\n",
    "            rewards=torch.tensor(sample[\"reward\"])[None],\n",
    "            next_states=torch.empty(1),\n",
    "            is_done=torch.tensor(sample[\"is_done\"])[None],\n",
    "            agent=agent,\n",
    "            target_network=tn,\n",
    "            gamma=sample[\"gamma\"],\n",
    "        ).item()\n",
    "        abs_diff = abs(ans - sample[\"answer\"])\n",
    "        print(f'abs_diff = abs(ans - sample[\"answer\"]): {abs_diff} = abs({ans} - {sample[\"answer\"]})')\n",
    "        assert abs_diff < 1e-8, abs_diff\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test_compute_td_loss_double(compute_td_loss: ComputeTdLossProtocol):\n",
    "    \"\"\"\n",
    "    Checks compute_td_loss on manually precomputed examples.\n",
    "    Note: this is a test for vanilla compute_td_loss\n",
    "    and it should NOT be used for double_dqn\n",
    "    \"\"\"\n",
    "\n",
    "    samples = [\n",
    "        {\n",
    "            \"q_agent\": [0, 1, 2],\n",
    "            \"action\": 1,\n",
    "            \"is_done\": False,\n",
    "            \"q_target\": [0, 1, 2],\n",
    "            \"gamma\": 0.5,\n",
    "            \"reward\": 5,\n",
    "            \"answer\": 25,\n",
    "        },\n",
    "        {\n",
    "            \"q_agent\": [0, 1, 2],\n",
    "            \"action\": 1,\n",
    "            \"is_done\": False,\n",
    "            \"q_target\": [2, 0, 1],\n",
    "            \"gamma\": 0.5,\n",
    "            \"reward\": 5,\n",
    "            \"answer\": 20.25,\n",
    "        },\n",
    "        {\n",
    "            \"q_agent\": [3, 1, 2],\n",
    "            \"action\": 1,\n",
    "            \"is_done\": False,\n",
    "            \"q_target\": [-1, 1, 2],\n",
    "            \"gamma\": 0.5,\n",
    "            \"reward\": 5,\n",
    "            \"answer\": 12.25,\n",
    "        },\n",
    "        {\n",
    "            \"q_agent\": [3, 1, 2],\n",
    "            \"action\": 1,\n",
    "            \"is_done\": True,\n",
    "            \"q_target\": [-1, 1, 2],\n",
    "            \"gamma\": 0.5,\n",
    "            \"reward\": 5,\n",
    "            \"answer\": 16,\n",
    "        },\n",
    "        {\n",
    "            \"q_agent\": [0, 1, 2],\n",
    "            \"action\": 0,\n",
    "            \"is_done\": False,\n",
    "            \"q_target\": [0, 1, 2],\n",
    "            \"gamma\": 0.5,\n",
    "            \"reward\": 5,\n",
    "            \"answer\": 36,\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    for sample in samples:\n",
    "        agent = MockAgent(torch.tensor(sample[\"q_agent\"], dtype=torch.float)[None])\n",
    "        tn = MockAgent(torch.tensor(sample[\"q_target\"], dtype=torch.float)[None])\n",
    "        ans = compute_td_loss(\n",
    "            states=torch.empty(1),\n",
    "            actions=torch.tensor(sample[\"action\"])[None],\n",
    "            rewards=torch.tensor(sample[\"reward\"])[None],\n",
    "            next_states=torch.empty(1),\n",
    "            is_done=torch.tensor(sample[\"is_done\"])[None],\n",
    "            agent=agent,\n",
    "            target_network=tn,\n",
    "            gamma=sample[\"gamma\"],\n",
    "        ).item()\n",
    "        abs_diff = abs(ans - sample[\"answer\"])\n",
    "        print(f'abs_diff = abs(ans - sample[\"answer\"]): {abs_diff} = abs({ans} - {sample[\"answer\"]})')\n",
    "        assert abs_diff < 1e-8, abs_diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "_vm3c2LLIZz4"
   },
   "outputs": [],
   "source": [
    "def compute_td_loss_on_tensors_double(\n",
    "    states: torch.Tensor,       # (batch_size, *state_shape)\n",
    "    actions: torch.Tensor,      # (batch_size,)\n",
    "    rewards: torch.Tensor,      # (batch_size,)\n",
    "    next_states: torch.Tensor,  # (batch_size, *state_shape)\n",
    "    is_done: torch.Tensor,      # (batch_size,), torch.bool\n",
    "    agent: nn.Module,\n",
    "    target_network: nn.Module,\n",
    "    gamma: float = 0.99,\n",
    "    check_shapes=False,\n",
    "):\n",
    "    predicted_qvalues = agent(states)  # shape: [batch_size, n_actions]\n",
    "    assert is_done.dtype is torch.bool\n",
    "\n",
    "    # compute q-values for all actions in next states\n",
    "    with torch.no_grad():\n",
    "        predicted_next_qvalues_target = target_network(next_states)  # shape: [batch_size, n_actions]\n",
    "\n",
    "    # select q-values for chosen actions (this is Q(s, a))\n",
    "    predicted_qvalues_for_actions = predicted_qvalues[\n",
    "        range(len(actions)), actions\n",
    "    ]  # shape: [batch_size]\n",
    "\n",
    "    predicted_next_qvalues = agent(next_states) # shape: [batch_size, n_actions]\n",
    "    argmax_actions = torch.argmax(predicted_next_qvalues, 1)[0]\n",
    "\n",
    "    predicted_target_qvalues_for_actions = predicted_next_qvalues_target[\n",
    "        range(len(actions)), argmax_actions\n",
    "    ]  # shape: [batch_size]\n",
    "\n",
    "    # compute V*(next_states) using predicted next q-values\n",
    "    next_state_values = torch.max(predicted_next_qvalues_target, 1)[0]\n",
    "    # In vanilla DQN this line here above is the max_a'_Q_target(s', a')\n",
    "\n",
    "    if check_shapes:\n",
    "        assert (\n",
    "            next_state_values.dim() == 1\n",
    "            and next_state_values.shape[0] == states.shape[0]\n",
    "        ), \"must predict one value per state\"\n",
    "        assert not next_state_values.requires_grad\n",
    "\n",
    "    # compute \"target q-values\" for loss - it's what's inside square parentheses in the above formula.\n",
    "    # at the last state use the simplified formula: Q(s,a) = r(s,a) since s' doesn't exist\n",
    "\n",
    "    #target_qvalues_for_actions =  rewards + (gamma * predicted_target_qvalues_for_actions if not is_done else 0)\n",
    "    # We cannot use the line above because it does not work with boolean vectors\n",
    "    target_qvalues_for_actions = torch.where(is_done, rewards, rewards + (gamma * predicted_target_qvalues_for_actions))\n",
    "\n",
    "    # mean squared error loss to minimize\n",
    "    loss = torch.mean((predicted_qvalues_for_actions - target_qvalues_for_actions) ** 2)\n",
    "\n",
    "    if check_shapes:\n",
    "        assert (\n",
    "            predicted_next_qvalues_target.data.dim() == 2\n",
    "        ), \"make sure you predicted q-values for all actions in next state\"\n",
    "        assert (\n",
    "            next_state_values.data.dim() == 1\n",
    "        ), \"make sure you computed V(s') as maximum over just the actions axis and not all axes\"\n",
    "        assert (\n",
    "            target_qvalues_for_actions.data.dim() == 1\n",
    "        ), \"there's something wrong with target q-values, they must be a vector\"\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PWz4tmZ4IZz4"
   },
   "source": [
    "**The following function works on np.ndarrays: it converts its inputs to torch.Tensors and calls the torch-tensor function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "0PppZrgoIZz4"
   },
   "outputs": [],
   "source": [
    "def compute_td_loss(\n",
    "    states,\n",
    "    actions,\n",
    "    rewards,\n",
    "    next_states,\n",
    "    is_done,\n",
    "    agent,\n",
    "    target_network,\n",
    "    gamma=0.99,\n",
    "    check_shapes=False,\n",
    "    device=None,\n",
    "    tensor_loss_evaluator=compute_td_loss_on_tensors_double,\n",
    "):\n",
    "    \"\"\"Compute td loss using torch operations only. Use the formulae above.\"\"\"\n",
    "\n",
    "    if device is None:\n",
    "        device = next(agent.parameters()).device\n",
    "    states = torch.tensor(\n",
    "        states, device=device, dtype=torch.float32\n",
    "    )  # shape: [batch_size, *state_shape]\n",
    "    actions = torch.tensor(\n",
    "        actions, device=device, dtype=torch.int64\n",
    "    )  # shape: [batch_size]\n",
    "    rewards = torch.tensor(\n",
    "        rewards, device=device, dtype=torch.float32\n",
    "    )  # shape: [batch_size]\n",
    "    # shape: [batch_size, *state_shape]\n",
    "    next_states = torch.tensor(next_states, device=device, dtype=torch.float)\n",
    "    is_done = torch.tensor(\n",
    "        is_done, device=device, dtype=torch.bool\n",
    "    )  # shape: [batch_size]\n",
    "\n",
    "    return tensor_loss_evaluator(\n",
    "        states=states,\n",
    "        actions=actions,\n",
    "        rewards=rewards,\n",
    "        next_states=next_states,\n",
    "        is_done=is_done,\n",
    "        agent=agent,\n",
    "        target_network=target_network,\n",
    "        gamma=gamma,\n",
    "        check_shapes=check_shapes,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x8AvquAtsoUG"
   },
   "source": [
    "Sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "5nRoOn30soUG"
   },
   "outputs": [],
   "source": [
    "obs_batch, act_batch, reward_batch, next_obs_batch, is_done_batch = exp_replay.sample(10)\n",
    "\n",
    "loss = compute_td_loss(obs_batch, act_batch, reward_batch, next_obs_batch, is_done_batch,\n",
    "                       agent, target_network,\n",
    "                       gamma=0.99, check_shapes=True)\n",
    "loss.backward()\n",
    "\n",
    "assert loss.requires_grad and tuple(loss.data.size()) == (), \\\n",
    "    \"you must return scalar loss - mean over batch\"\n",
    "assert np.any(next(agent.parameters()).grad.data.cpu().numpy() != 0), \\\n",
    "    \"loss must be differentiable w.r.t. network weights\"\n",
    "assert np.all(next(target_network.parameters()).grad is None), \\\n",
    "    \"target network should not have grads\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KIplL0hSsoUG"
   },
   "source": [
    "## Main loop (3 pts)\n",
    "\n",
    "**If deadline is tonight and it has not converged:** It is ok. Send the notebook today and when it converges send it again.\n",
    "If the code is exactly the same points will not be discounted.\n",
    "\n",
    "It's time to put everything together and see if it learns anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "-JV-ulB-soUG"
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import trange\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "mR0jiAAOIZz5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f63b40c18b0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "-eurxA-_soUG"
   },
   "outputs": [],
   "source": [
    "env = make_final_env()\n",
    "\n",
    "state, _ = env.reset(seed=seed)\n",
    "\n",
    "agent = DQNAgent(\n",
    "    DQNetworkDueling(N_FRAMES_STACKED, N_ACTIONS),\n",
    "    epsilon=1\n",
    ").to(device)\n",
    "target_network = DQNetworkDueling(N_FRAMES_STACKED, N_ACTIONS).to(device)\n",
    "target_network.load_state_dict(agent.q_network.state_dict())\n",
    "\n",
    "action_sampler = DqnActionSampler(agent)\n",
    "action_sampler_random = RandomActionSampler(env.action_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WZg25kIasoUG"
   },
   "source": [
    "Buffer of size $10^4$ can probably pass the threshold for this assignment.\n",
    "\n",
    "Larger sizes ($10^5$ and $10^6$ are common) can show a much higher score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "hWyMxfN4soUG",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afaf5a69bb564aef8731be694b7e89f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "REPLAY_BUFFER_SIZE = 10**6\n",
    "# INITIAL_BUFFER_FILL = 50_000  # Nature DQN Extended Data Table 1\n",
    "INITIAL_BUFFER_FILL = 200_000  # Rainbow without prioritization\n",
    "_n_steps = 100\n",
    "\n",
    "exp_replay = ReplayBuffer(REPLAY_BUFFER_SIZE)\n",
    "for i in trange(INITIAL_BUFFER_FILL // _n_steps):\n",
    "    if not is_enough_ram(min_available_gb=0.1):\n",
    "        print(\"\"\"\n",
    "            Less than 100 Mb RAM available.\n",
    "            Make sure the buffer size in not too huge.\n",
    "            Also check, maybe other processes consume RAM heavily.\n",
    "            \"\"\"\n",
    "             )\n",
    "        break\n",
    "    play_and_record(state, action_sampler_random, env, exp_replay, n_steps=_n_steps)\n",
    "    if len(exp_replay) >= INITIAL_BUFFER_FILL:\n",
    "        break\n",
    "print(len(exp_replay))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "EmOkMP9ZIZz5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(exp_replay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "_ca9vbW4soUG"
   },
   "outputs": [],
   "source": [
    "update_frequency = 4  # n_steps for play_and_record; Nature DQN Extended Data Table 1 + Rainbow Table 4: Additional hyper-parameters\n",
    "batch_size = 32  # Nature DQN Extended Data Table 1 + Table 4: Additional hyper-parameters\n",
    "total_steps = 10 * 10**6  # this can be long, feel free to stop the training when the target score is reached\n",
    "decay_steps = 10**6  # Nature DQN Extended Data Table 1\n",
    "\n",
    "opt = torch.optim.Adam(agent.parameters(), lr=6.25e-05, eps=1.4e-4)  # Rainbow\n",
    "\n",
    "init_epsilon = 1  # Nature DQN\n",
    "final_epsilon = 0.1  # Nature DQN\n",
    "\n",
    "loss_freq = 100\n",
    "refresh_target_network_freq = 10_000  # Nature DQN\n",
    "eval_freq = 10_000\n",
    "\n",
    "max_grad_norm = 10  # Dueling DQN\n",
    "\n",
    "n_lives = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "oJWs0q-6soUG"
   },
   "outputs": [],
   "source": [
    "step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "675-JU0hsoUG"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def wait_for_keyboard_interrupt():\n",
    "    try:\n",
    "        while True:\n",
    "            time.sleep(1)\n",
    "    except KeyboardInterrupt:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "qg0JVAEqIZz6"
   },
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "20Mf7_qYIZz6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1c80317fa3b1799d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1c80317fa3b1799d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "FgQ1vK3CsoUG",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buffer size = 1000000, epsilon = 0.10000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     22\u001b[0m grad_norm \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(agent\u001b[38;5;241m.\u001b[39mparameters(), max_grad_norm)\n\u001b[0;32m---> 23\u001b[0m \u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m%\u001b[39m loss_freq \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/envs/rlearn/lib/python3.10/site-packages/torch/optim/optimizer.py:88\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/envs/rlearn/lib/python3.10/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/envs/rlearn/lib/python3.10/site-packages/torch/optim/adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[38;5;66;03m# record the step after step update\u001b[39;00m\n\u001b[1;32m    139\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 141\u001b[0m     \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m           \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m           \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m           \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m           \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m           \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m           \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m           \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m           \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m           \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m           \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m           \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m           \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/envs/rlearn/lib/python3.10/site-packages/torch/optim/_functional.py:105\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    103\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(bias_correction2))\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m     denom \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbias_correction2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m step_size \u001b[38;5;241m=\u001b[39m lr \u001b[38;5;241m/\u001b[39m bias_correction1\n\u001b[1;32m    110\u001b[0m param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env = make_final_env()\n",
    "state, _ = env.reset()\n",
    "with trange(step, total_steps + 1) as progress_bar:\n",
    "    for step in progress_bar:\n",
    "        if not is_enough_ram():\n",
    "            print('less that 100 Mb RAM available, freezing')\n",
    "            print('make sure everything is ok and use KeyboardInterrupt to continue')\n",
    "            wait_for_keyboard_interrupt()\n",
    "\n",
    "        agent.epsilon = linear_decay(init_epsilon, final_epsilon, step, decay_steps)\n",
    "\n",
    "        # play\n",
    "        _, state = play_and_record(state, action_sampler, env, exp_replay, n_steps=update_frequency)\n",
    "\n",
    "        # train\n",
    "        s, a, r, s_next, done = exp_replay.sample(batch_size)\n",
    "\n",
    "        # we're using the standard loss, not double DQN\n",
    "        loss = compute_td_loss(s, a, r, s_next, done, agent, target_network, device=device)\n",
    "\n",
    "        loss.backward()\n",
    "        grad_norm = nn.utils.clip_grad_norm_(agent.parameters(), max_grad_norm)\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "        if step % loss_freq == 0:\n",
    "            writer.add_scalar(\"loss\", loss.data.cpu().item(), step)\n",
    "            writer.add_scalar(\"grad_norm\", grad_norm.cpu().item(), step)\n",
    "\n",
    "        if step % refresh_target_network_freq == 0:\n",
    "            # Load agent weights into target_network\n",
    "            target_network.load_state_dict(agent.q_network.state_dict())\n",
    "            torch.save(agent.state_dict(), \"last_state_dict.pt\")\n",
    "\n",
    "        if step % eval_freq == 0:\n",
    "            mean_reward = evaluate(\n",
    "                make_final_env(), agent, n_games=3 * n_lives, greedy=True, seed=step\n",
    "            )\n",
    "            writer.add_scalar(\"mean_reward_per_life\", mean_reward, step)\n",
    "\n",
    "            initial_state_q_values = agent.get_qvalues(\n",
    "                [make_final_env().reset(seed=step)[0]]\n",
    "            )\n",
    "            writer.add_scalar(\"initial_state_v\", np.max(initial_state_q_values).item(), step)\n",
    "\n",
    "            clear_output(True)\n",
    "            print(\"buffer size = %i, epsilon = %.5f\" %\n",
    "                (len(exp_replay), agent.epsilon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "jv13btLrIZz6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = DQNAgent(\n",
    "    DQNetworkDueling(N_FRAMES_STACKED, N_ACTIONS),\n",
    "    epsilon=1\n",
    ").to(device)\n",
    "agent.load_state_dict(torch.load(\"last_state_dict.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZEDQhQrdsoUG"
   },
   "source": [
    "Agent is evaluated for 1 life, not for a whole episode of 5 lives. Rewards in evaluation are also truncated. Cuz this is what environment the agent is learning in and in this way mean rewards per life can be compared with initial state value\n",
    "\n",
    "**The goal is to get 15 points in the real env**. So 3 or better 4 points in the preprocessed one will probably be enough. You can interrupt learning then."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s0jLjYGwsoUG"
   },
   "source": [
    "Final scoring is done on a whole episode with all 5 lives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "xTGVrwwQsoUG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final score: 8.0\n",
      "Cool!\n"
     ]
    }
   ],
   "source": [
    "final_score = evaluate(\n",
    "  make_final_env(),\n",
    "    agent, n_games=30, greedy=True, t_max=10 * 1000, seed=9\n",
    ")\n",
    "print('final score:', final_score)\n",
    "assert final_score >= 3, 'not as cool as DQN can'\n",
    "print('Cool!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ovaG8N4lsoUH"
   },
   "source": [
    "## How to interpret plots:\n",
    "\n",
    "This aint no supervised learning so don't expect anything to improve monotonously.\n",
    "* **TD loss** is the MSE between agent's current Q-values and target Q-values. It may slowly increase or decrease, it's ok. The \"not ok\" behavior includes going NaN or stayng at exactly zero before agent has perfect performance.\n",
    "* **grad norm** just shows the intensivity of training. Not ok is growing to values of about 100 (or maybe even 50) though it depends on network architecture.\n",
    "* **mean reward** is the expected sum of r(s,a) agent gets over the full game session. It will oscillate, but on average it should get higher over time (after a few thousand iterations...).\n",
    " * In basic q-learning implementation it takes about 40k steps to \"warm up\" agent before it starts to get better.\n",
    "* **Initial state V** is the expected discounted reward for episode in the oppinion of the agent. It should behave more smoothly than **mean reward**. It should get higher over time but sometimes can experience drawdowns because of the agaent's overestimates.\n",
    "* **buffer size** - this one is simple. It should go up and cap at max size.\n",
    "* **epsilon** - agent's willingness to explore. If you see that agent's already at 0.01 epsilon before it's average reward is above 0 - it means you need to increase epsilon. Set it back to some 0.2 - 0.5 and decrease the pace at which it goes down.\n",
    "* Smoothing of plots is done with a gaussian kernel\n",
    "\n",
    "At first your agent will lose quickly. Then it will learn to suck less and at least hit the ball a few times before it loses. Finally it will learn to actually score points.\n",
    "\n",
    "**Training will take time.** A lot of it actually. Probably you will not see any improvment during first **150k** time steps (note that by default in this notebook agent is evaluated every 5000 time steps).\n",
    "\n",
    "But hey, long training time isn't _that_ bad:\n",
    "![img](https://github.com/yandexdataschool/Practical_RL/raw/master/yet_another_week/_resource/training.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kVV72AB-soUH"
   },
   "source": [
    "## About hyperparameters:\n",
    "\n",
    "The task has something in common with supervised learning: loss is optimized through the buffer (instead of Train dataset). But the distribution of states and actions in the buffer **is not stationary** and depends on the policy it was generated by. It can even happen that the mean TD error across the buffer is very low but the performance is extremely poor (imagine the agent collecting data to the buffer always manages to avoid the ball).\n",
    "\n",
    "* Total timesteps and training time: It seems to be so huge, but actually it is normal for RL.\n",
    "\n",
    "* $\\epsilon$ decay shedule was taken from the original paper and is like traditional for epsilon-greedy policies. At the beginning of the training the agent's greedy policy is poor so many random actions should be taken.\n",
    "\n",
    "* Optimizer: In the original paper RMSProp was used (they did not have Adam in 2013) and it can work not worse than Adam. For us Adam was default and it worked.\n",
    "\n",
    "* lr: $10^{-3}$ would probably be too huge\n",
    "\n",
    "* target network update frequency: has something in common with learning rate. Too frequent updates can lead to divergence. Too rare can lead to slow leraning. For millions of total timesteps thousands of inner steps seem ok. One iteration of target network updating is an iteration of the (this time approximate) $\\gamma$-compression that stands behind Q-learning. The more inner steps it makes the more accurate is the compression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Plp8WC_esoUH"
   },
   "source": [
    "### Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "DdExc_AssoUH"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/george/envs/rlearn/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:335: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/george/RL/videos/rl-video-episode-0.mp4.\n",
      "Moviepy - Writing video /home/george/RL/videos/rl-video-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/george/RL/videos/rl-video-episode-0.mp4\n",
      "Moviepy - Building video /home/george/RL/videos/rl-video-episode-1.mp4.\n",
      "Moviepy - Writing video /home/george/RL/videos/rl-video-episode-1.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/george/RL/videos/rl-video-episode-1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/george/RL/videos/rl-video-episode-2.mp4.\n",
      "Moviepy - Writing video /home/george/RL/videos/rl-video-episode-2.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/george/RL/videos/rl-video-episode-2.mp4\n",
      "Moviepy - Building video /home/george/RL/videos/rl-video-episode-3.mp4.\n",
      "Moviepy - Writing video /home/george/RL/videos/rl-video-episode-3.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/george/RL/videos/rl-video-episode-3.mp4\n",
      "Moviepy - Building video /home/george/RL/videos/rl-video-episode-4.mp4.\n",
      "Moviepy - Writing video /home/george/RL/videos/rl-video-episode-4.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/george/RL/videos/rl-video-episode-4.mp4\n",
      "Moviepy - Building video /home/george/RL/videos/rl-video-episode-5.mp4.\n",
      "Moviepy - Writing video /home/george/RL/videos/rl-video-episode-5.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/george/RL/videos/rl-video-episode-5.mp4\n",
      "Moviepy - Building video /home/george/RL/videos/rl-video-episode-6.mp4.\n",
      "Moviepy - Writing video /home/george/RL/videos/rl-video-episode-6.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/george/RL/videos/rl-video-episode-6.mp4\n",
      "Moviepy - Building video /home/george/RL/videos/rl-video-episode-7.mp4.\n",
      "Moviepy - Writing video /home/george/RL/videos/rl-video-episode-7.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/george/RL/videos/rl-video-episode-7.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/george/RL/videos/rl-video-episode-8.mp4.\n",
      "Moviepy - Writing video /home/george/RL/videos/rl-video-episode-8.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/george/RL/videos/rl-video-episode-8.mp4\n",
      "Moviepy - Building video /home/george/RL/videos/rl-video-episode-9.mp4.\n",
      "Moviepy - Writing video /home/george/RL/videos/rl-video-episode-9.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/george/RL/videos/rl-video-episode-9.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/george/RL/videos/rl-video-episode-10.mp4.\n",
      "Moviepy - Writing video /home/george/RL/videos/rl-video-episode-10.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/george/RL/videos/rl-video-episode-10.mp4\n",
      "Moviepy - Building video /home/george/RL/videos/rl-video-episode-11.mp4.\n",
      "Moviepy - Writing video /home/george/RL/videos/rl-video-episode-11.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/george/RL/videos/rl-video-episode-11.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/george/RL/videos/rl-video-episode-12.mp4.\n",
      "Moviepy - Writing video /home/george/RL/videos/rl-video-episode-12.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/george/RL/videos/rl-video-episode-12.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/george/RL/videos/rl-video-episode-13.mp4.\n",
      "Moviepy - Writing video /home/george/RL/videos/rl-video-episode-13.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/george/RL/videos/rl-video-episode-13.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/george/RL/videos/rl-video-episode-14.mp4.\n",
      "Moviepy - Writing video /home/george/RL/videos/rl-video-episode-14.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/george/RL/videos/rl-video-episode-14.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/george/RL/videos/rl-video-episode-15.mp4.\n",
      "Moviepy - Writing video /home/george/RL/videos/rl-video-episode-15.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/george/RL/videos/rl-video-episode-15.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/george/RL/videos/rl-video-episode-16.mp4.\n",
      "Moviepy - Writing video /home/george/RL/videos/rl-video-episode-16.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/george/RL/videos/rl-video-episode-16.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/george/RL/videos/rl-video-episode-17.mp4.\n",
      "Moviepy - Writing video /home/george/RL/videos/rl-video-episode-17.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/george/RL/videos/rl-video-episode-17.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/george/RL/videos/rl-video-episode-18.mp4.\n",
      "Moviepy - Writing video /home/george/RL/videos/rl-video-episode-18.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/george/RL/videos/rl-video-episode-18.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/george/RL/videos/rl-video-episode-19.mp4.\n",
      "Moviepy - Writing video /home/george/RL/videos/rl-video-episode-19.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/george/RL/videos/rl-video-episode-19.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/george/RL/videos/rl-video-episode-20.mp4.\n",
      "Moviepy - Writing video /home/george/RL/videos/rl-video-episode-20.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/george/RL/videos/rl-video-episode-20.mp4\n",
      "Moviepy - Building video /home/george/RL/videos/rl-video-episode-21.mp4.\n",
      "Moviepy - Writing video /home/george/RL/videos/rl-video-episode-21.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/george/RL/videos/rl-video-episode-21.mp4\n",
      "Moviepy - Building video /home/george/RL/videos/rl-video-episode-22.mp4.\n",
      "Moviepy - Writing video /home/george/RL/videos/rl-video-episode-22.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/george/RL/videos/rl-video-episode-22.mp4\n",
      "Moviepy - Building video /home/george/RL/videos/rl-video-episode-23.mp4.\n",
      "Moviepy - Writing video /home/george/RL/videos/rl-video-episode-23.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/george/RL/videos/rl-video-episode-23.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/george/RL/videos/rl-video-episode-24.mp4.\n",
      "Moviepy - Writing video /home/george/RL/videos/rl-video-episode-24.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/george/RL/videos/rl-video-episode-24.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/george/RL/videos/rl-video-episode-25.mp4.\n",
      "Moviepy - Writing video /home/george/RL/videos/rl-video-episode-25.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/george/RL/videos/rl-video-episode-25.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/george/RL/videos/rl-video-episode-26.mp4.\n",
      "Moviepy - Writing video /home/george/RL/videos/rl-video-episode-26.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/george/RL/videos/rl-video-episode-26.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/george/RL/videos/rl-video-episode-27.mp4.\n",
      "Moviepy - Writing video /home/george/RL/videos/rl-video-episode-27.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/george/RL/videos/rl-video-episode-27.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/george/RL/videos/rl-video-episode-28.mp4.\n",
      "Moviepy - Writing video /home/george/RL/videos/rl-video-episode-28.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/george/RL/videos/rl-video-episode-28.mp4\n",
      "Moviepy - Building video /home/george/RL/videos/rl-video-episode-29.mp4.\n",
      "Moviepy - Writing video /home/george/RL/videos/rl-video-episode-29.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/george/RL/videos/rl-video-episode-29.mp4\n",
      "Moviepy - Building video /home/george/RL/videos/rl-video-episode-30.mp4.\n",
      "Moviepy - Writing video /home/george/RL/videos/rl-video-episode-30.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/george/RL/videos/rl-video-episode-30.mp4\n",
      "Moviepy - Building video /home/george/RL/videos/rl-video-episode-31.mp4.\n",
      "Moviepy - Writing video /home/george/RL/videos/rl-video-episode-31.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/george/RL/videos/rl-video-episode-31.mp4\n",
      "Moviepy - Building video /home/george/RL/videos/rl-video-episode-32.mp4.\n",
      "Moviepy - Writing video /home/george/RL/videos/rl-video-episode-32.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/george/RL/videos/rl-video-episode-32.mp4\n",
      "Moviepy - Building video /home/george/RL/videos/rl-video-episode-33.mp4.\n",
      "Moviepy - Writing video /home/george/RL/videos/rl-video-episode-33.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/george/RL/videos/rl-video-episode-33.mp4\n",
      "Moviepy - Building video /home/george/RL/videos/rl-video-episode-34.mp4.\n",
      "Moviepy - Writing video /home/george/RL/videos/rl-video-episode-34.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/george/RL/videos/rl-video-episode-34.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/george/RL/videos/rl-video-episode-35.mp4.\n",
      "Moviepy - Writing video /home/george/RL/videos/rl-video-episode-35.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/george/RL/videos/rl-video-episode-35.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/george/RL/videos/rl-video-episode-36.mp4.\n",
      "Moviepy - Writing video /home/george/RL/videos/rl-video-episode-36.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/george/RL/videos/rl-video-episode-36.mp4\n",
      "Moviepy - Building video /home/george/RL/videos/rl-video-episode-37.mp4.\n",
      "Moviepy - Writing video /home/george/RL/videos/rl-video-episode-37.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/george/RL/videos/rl-video-episode-37.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/george/RL/videos/rl-video-episode-38.mp4.\n",
      "Moviepy - Writing video /home/george/RL/videos/rl-video-episode-38.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/george/RL/videos/rl-video-episode-38.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/george/RL/videos/rl-video-episode-39.mp4.\n",
      "Moviepy - Writing video /home/george/RL/videos/rl-video-episode-39.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/george/RL/videos/rl-video-episode-39.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/george/RL/videos/rl-video-episode-40.mp4.\n",
      "Moviepy - Writing video /home/george/RL/videos/rl-video-episode-40.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/george/RL/videos/rl-video-episode-40.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/george/RL/videos/rl-video-episode-41.mp4.\n",
      "Moviepy - Writing video /home/george/RL/videos/rl-video-episode-41.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/george/RL/videos/rl-video-episode-41.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/george/RL/videos/rl-video-episode-42.mp4.\n",
      "Moviepy - Writing video /home/george/RL/videos/rl-video-episode-42.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/george/RL/videos/rl-video-episode-42.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/george/RL/videos/rl-video-episode-43.mp4.\n",
      "Moviepy - Writing video /home/george/RL/videos/rl-video-episode-43.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/george/RL/videos/rl-video-episode-43.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/george/RL/videos/rl-video-episode-44.mp4.\n",
      "Moviepy - Writing video /home/george/RL/videos/rl-video-episode-44.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/george/RL/videos/rl-video-episode-44.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/george/RL/videos/rl-video-episode-45.mp4.\n",
      "Moviepy - Writing video /home/george/RL/videos/rl-video-episode-45.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/george/RL/videos/rl-video-episode-45.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/george/RL/videos/rl-video-episode-46.mp4.\n",
      "Moviepy - Writing video /home/george/RL/videos/rl-video-episode-46.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/george/RL/videos/rl-video-episode-46.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/george/RL/videos/rl-video-episode-47.mp4.\n",
      "Moviepy - Writing video /home/george/RL/videos/rl-video-episode-47.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/george/RL/videos/rl-video-episode-47.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/george/RL/videos/rl-video-episode-48.mp4.\n",
      "Moviepy - Writing video /home/george/RL/videos/rl-video-episode-48.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/george/RL/videos/rl-video-episode-48.mp4\n",
      "Moviepy - Building video /home/george/RL/videos/rl-video-episode-49.mp4.\n",
      "Moviepy - Writing video /home/george/RL/videos/rl-video-episode-49.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/george/RL/videos/rl-video-episode-49.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# record sessions\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "\n",
    "with make_final_env() as env, RecordVideo(\n",
    "    env=env, video_folder=\"./videos\", episode_trigger=lambda episode_number: True\n",
    ") as env_monitor:\n",
    "    sessions = [\n",
    "        evaluate(env_monitor, agent, n_games=n_lives, greedy=True) for _ in range(10)\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "lt6xg1n_soUH"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"640\" height=\"480\" controls>\n",
       "  <source src=\"videos/rl-video-episode-9.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show video. This may not work in some setups. If it doesn't\n",
    "# work for you, you can download the videos and view them locally.\n",
    "\n",
    "from pathlib import Path\n",
    "from base64 import b64encode\n",
    "from IPython.display import HTML\n",
    "\n",
    "video_paths = sorted([s for s in Path('videos').iterdir() if s.suffix == '.mp4'])\n",
    "video_path = video_paths[-1]  # You can also try other indices\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    # https://stackoverflow.com/a/57378660/1214547\n",
    "    with video_path.open('rb') as fp:\n",
    "        mp4 = fp.read()\n",
    "    data_url = 'data:video/mp4;base64,' + b64encode(mp4).decode()\n",
    "else:\n",
    "    data_url = str(video_path)\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"{}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format(data_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fLPx2aI7soUH"
   },
   "source": [
    "## Let's have a closer look at this. Interpretation (2 pts).\n",
    "\n",
    "Let's play 5 episodes (note that the game has 5 lives) and log some stats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from collections.abc import Reversible\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def play_and_log_episode(env, agent, t_max=10000):\n",
    "    \"\"\"\n",
    "    Plays an episode using the greedy policy and logs for each timestep:\n",
    "    - state\n",
    "    - qvalues (estimated by the agent)\n",
    "    - actions\n",
    "    - rewards\n",
    "\n",
    "    Also logs:\n",
    "    - the final (usually termo=inal) state.\n",
    "    - whether the episode was terminated\n",
    "\n",
    "    Uses the greedy policy.\n",
    "    \"\"\"\n",
    "    assert t_max > 0, t_max\n",
    "\n",
    "    states = []\n",
    "    qvalues_all = []\n",
    "    actions = []\n",
    "    rewards = []\n",
    "\n",
    "    s, _ = env.reset()\n",
    "    for step in range(t_max):\n",
    "        s = np.array(s)\n",
    "        states.append(s)\n",
    "        qvalues = agent.get_qvalues(s[None])[0]\n",
    "        qvalues_all.append(qvalues)\n",
    "        action = np.argmax(qvalues)\n",
    "        actions.append(action)\n",
    "        s, r, terminated, truncated, _ = env.step(action)\n",
    "        rewards.append(r)\n",
    "        if terminated or truncated:\n",
    "            break\n",
    "    states.append(s)  # the last state\n",
    "\n",
    "    return_pack = {\n",
    "        \"states\": np.array(states),\n",
    "        \"qvalues\": np.array(qvalues_all),\n",
    "        \"actions\": np.array(actions),\n",
    "        \"rewards\": np.array(rewards),\n",
    "        \"episode_finished\": terminated,\n",
    "    }\n",
    "\n",
    "    return return_pack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "0vlQG4iQIZz7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: ['states', 'qvalues', 'actions', 'rewards', 'episode_finished']\n",
      "Shapes:\n",
      "states: (442, 4, 84, 84)\n",
      "qvalues: (441, 4)\n",
      "actions: (441,)\n",
      "rewards: (441,)\n",
      "terminated: True\n"
     ]
    }
   ],
   "source": [
    "env = make_final_env()\n",
    "stats = play_and_log_episode(env, agent)\n",
    "\n",
    "print(\"Keys:\", list(stats.keys()))\n",
    "print(\"Shapes:\")\n",
    "for key in [\"states\", \"qvalues\", \"actions\", \"rewards\"]:\n",
    "    print(f\"{key}: {stats[key].shape}\")\n",
    "print(\"terminated:\", stats[\"episode_finished\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "29AwhtFzIZz7"
   },
   "source": [
    "Let's plot rewards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "K-POmyUcIZz8"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(stats[\"rewards\"])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZzfH82w3IZz8"
   },
   "source": [
    "Your task it to evaluate the following quantities from the logs:\n",
    "1. Discounted returns: $G[t] = \\sum_{t'=t}^T \\gamma ^ {t' - t}r[t]$, where $T$ is the total time of an episode.\n",
    "2. State Values estimated by the agent: $V_{agent}[t] = \\max_{a}Q_{agent}(s[t], a)$.\n",
    "3. Q-spread: $\\Delta Q[t] = \\max_{a}Q_{agent}(s[t], a) - \\min_{a}Q_{agent}(s[t], a)$\n",
    "\n",
    "Create a new env: `env = make_final_env()`, play for 5 episodes (a full game has 5 lives, so it will be 1 full game).  \n",
    "Plot rewards and the evaluated quantites for each of them.  \n",
    "Using the plots, can you find points where the ball hits the wall?  \n",
    "Where the ball hits the platform?  \n",
    "Probably, you won't need all the quantities for that, but it's still good to check the behavior of a model.\n",
    "\n",
    "The `merge_frame_stack_to_plot` function may be useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e36bU0u8soUH"
   },
   "source": [
    "## Bonus I (2 pts). Get High Score!\n",
    "\n",
    "Get mean reward per life:\n",
    "1. $\\geq 20$: +1 pt\n",
    "2. $\\geq 40$: +2 pts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "78e4nRoSsoUH"
   },
   "source": [
    "## Bonus II (2+ pts). Apply modifications to DQN.\n",
    "\n",
    "* [Prioritized experience replay](https://arxiv.org/abs/1511.05952) (2 pts, please check for effective open-source implementations)\n",
    "* [Noisy Nets](https://arxiv.org/abs/1706.10295) (2 pts, please, pay attention to the exploration policy and whether epsilon-greedy policy is used)\n",
    "* [distributional RL](https://arxiv.org/abs/1707.06887)(distributional and distributed stand for different things here) (3 pts)\n",
    "* Other modifications (2+ pts depending on complexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j_3RXboysoUH"
   },
   "source": [
    "## Bonus III (2 pts). Distributed RL.\n",
    "\n",
    "https://gymnasium.farama.org/api/vector/#gymnasium.vector.AsyncVectorEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f9X5aB56soUI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
